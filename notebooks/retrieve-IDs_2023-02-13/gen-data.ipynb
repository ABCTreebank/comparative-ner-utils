{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import json\n",
    "import itertools\n",
    "\n",
    "import datasets\n",
    "\n",
    "import abctk.obj.comparative as aoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "ANNOT_FILE_PATH = \"/home/owner/ABCT/comp-proto/comparative-annotation_linearized_2023-02-14.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-935290dee194d9be\n",
      "Found cached dataset parquet (/home/owner/.cache/huggingface/datasets/abctreebank___parquet/default-935290dee194d9be/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b07760079a2e42e48358750f6b7cde74",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load previous dataset from the HF repo\n",
    "dataset_raw = datasets.load_dataset(\n",
    "    \"abctreebank/comparative-NER-BCCWJ\",\n",
    "    use_auth_token = True,\n",
    "    revision = \"e3cdaf016f1fba88d10194500c313f951b0d2df3\",\n",
    ")\n",
    "\n",
    "# Just in order to and comments\n",
    "dataset_train = dataset_raw[\"train\"]\n",
    "dataset_test = dataset_raw[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# index datasets\n",
    "dataset_indexed: dict[str, dict] = dict(\n",
    "    (item[\"ID\"], item)\n",
    "    for item in datasets.concatenate_datasets(\n",
    "        [dataset_raw[\"train\"], dataset_test ]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load current annotation file\n",
    "with open(ANNOT_FILE_PATH) as g:\n",
    "    annots = tuple(aoc.read_bracket_annotation_file(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Incorporate comments\n",
    "for annot_record in annots:\n",
    "    current_ID = annot_record[\"ID\"]\n",
    "    record_in_dataset = dataset_indexed[current_ID]\n",
    "\n",
    "    annot_record[\"comments\"] = list(\n",
    "        set(\n",
    "            itertools.chain(\n",
    "                annot_record.get(\"comments\", []),\n",
    "                record_in_dataset.get(\"comments\", []),\n",
    "            )\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod newly found IDs\n",
    "with open(\"./ID-mapping.csv\") as f:\n",
    "    reader = csv.DictReader(\n",
    "        f,\n",
    "        fieldnames = [\n",
    "            \"ID_current\",\n",
    "            \"found_bccwj_file\",\n",
    "            \"found_bccwj_start\",\n",
    "            \"correct_bccwj_file\",\n",
    "            \"correct_bccwj_start\"\n",
    "        ],\n",
    "        dialect=\"excel\",\n",
    "    )\n",
    "\n",
    "    _ = next(reader)\n",
    "\n",
    "    # make indices\n",
    "    mapping = dict( \n",
    "        (row[\"ID_current\"], row) \n",
    "        for row in reader\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "_RE_kurabe = re.compile(r\"kurabe\")\n",
    "\n",
    "def generate_new_ID(ID_current: str, bccwj_file, bccwj_start)-> str:\n",
    "    kind = (\n",
    "        \"kurabe\"\n",
    "        if _RE_kurabe.search(ID_current) \n",
    "        else \"yori\"\n",
    "    )\n",
    "\n",
    "    if bccwj_file and bccwj_start:\n",
    "        return f\"ABCT-COMP-BCCWJ;{kind};{bccwj_file},{bccwj_start}\"\n",
    "    else:\n",
    "        return f\"ABCT-COMP-BCCWJ;{kind};UNKNOWN,UNKNOWN\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change IDs\n",
    "for annot_record in annots:\n",
    "    current_ID = annot_record[\"ID\"]\n",
    "    annot_record[\"ID_v1\"] = current_ID\n",
    "    match = mapping[current_ID]\n",
    "    if match[\"correct_bccwj_file\"] and match[\"correct_bccwj_start\"]:\n",
    "        annot_record[\"ID\"] = generate_new_ID(\n",
    "            current_ID,\n",
    "            match[\"correct_bccwj_file\"],\n",
    "             match[\"correct_bccwj_start\"],\n",
    "        )\n",
    "    else:\n",
    "        annot_record[\"ID\"] = generate_new_ID(\n",
    "            current_ID,\n",
    "            match[\"found_bccwj_file\"],\n",
    "            match[\"found_bccwj_start\"],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# collect test sentence IDs\n",
    "test_IDs = set(record[\"ID\"] for record in dataset_test)\n",
    "\n",
    "# Split train/test\n",
    "annots_train = tuple(\n",
    "    r for r in annots\n",
    "    if r[\"ID_v1\"] not in test_IDs\n",
    ")\n",
    "\n",
    "annots_test = tuple(\n",
    "    r for r in annots\n",
    "    if r[\"ID_v1\"] in test_IDs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"train.jsonl\", \"w\") as f_train:\n",
    "    for record in annots_train:\n",
    "        json.dump(record, f_train, ensure_ascii = False)\n",
    "        f_train.write(\"\\n\")\n",
    "\n",
    "with open(\"test.jsonl\", \"w\") as f_test:\n",
    "    for record in annots_test:\n",
    "        json.dump(record, f_test, ensure_ascii = False)\n",
    "        f_test.write(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Put the generated two JSONL files to the dataset folder and do HF push_to_hub.\n",
    "\n",
    "```sh\n",
    "mv train.sjon test.jsonl ../comparative-NER-BCCWJ/\n",
    "abct-comp-ner-utils upload-data --private ./comparative-NER-BCCWJ\n",
    "```\n",
    "\n",
    "WARNING: do not stage any annotation data to this repo so as to keep them private."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comparative-ner-utils-sv0RmVnD-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98ff88495b25d3c68e7ba2c5383ef33c76229d3a0872ace53e941ddd39c21b36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
