{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 報告 2022-10-19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "cat ~/ABCT/comp-proto/Annotation-complete-IDed/BCCWJ-ABC*.psd | munge-trees -w > /tmp/comp-yori.psd\n",
    "cat ~/ABCT/comp-proto/Annotation-complete-IDed/bccwj_kurabe_*.psd | munge-trees -w > /tmp/comp-kurabe.psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「より」の文数\n",
    "COUNT_YORI, *_ = ! cat /tmp/comp-yori.psd | wc -l\n",
    "COUNT_YORI = int(COUNT_YORI)\n",
    "\n",
    "# 「より」のうち，単文の数\n",
    "# NOTE: CPに関しては，全て単文であることを目視済み。\n",
    "# NOTE: tregex options: -s: one-liner, -w: whole tree\n",
    "COUNT_YORI_SIMPLE, *_ = ! tregex -s -w '/^(VPm|VPsub|Sm|Ssub|CP)/ == /root/' /tmp/comp-yori.psd 2> /dev/null | sort | uniq | wc -l \n",
    "COUNT_YORI_SIMPLE = int(COUNT_YORI_SIMPLE)\n",
    "\n",
    "# 「より」のうち，連用節の数\n",
    "COUNT_YORI_ADVERBIAL, *_ = ! tregex -s -w '/^(VPa|Sa)/ == /root/' /tmp/comp-yori.psd 2> /dev/null | sort | uniq | wc -l \n",
    "COUNT_YORI_ADVERBIAL = int(COUNT_YORI_ADVERBIAL)\n",
    "\n",
    "# 「より」のうち，連体節の数\n",
    "COUNT_YORI_ADNOMINAL, *_ =  ! tregex -s -w '/^(VPrel|Srel|N)/ == /root/' /tmp/comp-yori.psd 2> /dev/null | sort | uniq | wc -l \n",
    "COUNT_YORI_ADNOMINAL = int(COUNT_YORI_ADNOMINAL)\n",
    "\n",
    "# そもそも比較構文でない物の数\n",
    "COUNT_YORI_NA, *_ = ! cat /tmp/comp-yori.psd | sed -e '/#comp/d' | wc -l\n",
    "COUNT_YORI_NA = int(COUNT_YORI_NA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「比べて」の文数\n",
    "COUNT_KURABE, *_ = ! cat /tmp/comp-kurabe.psd | wc -l\n",
    "COUNT_KURABE = int(COUNT_KURABE)\n",
    "\n",
    "# 「比べて」のうち，単文の数\n",
    "# NOTE: CPに関しては，全て単文であることを目視済み。\n",
    "# NOTE: tregex options: -s: one-liner, -w: whole tree\n",
    "COUNT_KURABE_SIMPLE, *_ = ! tregex -s -w '/^(VPm|VPsub|Sm|Ssub|CP)/ == /root/' /tmp/comp-kurabe.psd 2> /dev/null | sort | uniq | wc -l \n",
    "COUNT_KURABE_SIMPLE = int(COUNT_KURABE_SIMPLE)\n",
    "\n",
    "# 「比べて」のうち，連用節の数\n",
    "COUNT_KURABE_ADVERBIAL, *_ = ! tregex -s -w '/^(VPa|Sa)/ == /root/' /tmp/comp-kurabe.psd 2> /dev/null | sort | uniq | wc -l \n",
    "COUNT_KURABE_ADVERBIAL = int(COUNT_KURABE_ADVERBIAL)\n",
    "\n",
    "# 「比べて」のうち，連体節の数\n",
    "COUNT_KURABE_ADNOMINAL, *_ =  ! tregex -s -w '/^(VPrel|Srel|N)/ == /root/' /tmp/comp-kurabe.psd 2> /dev/null | sort | uniq | wc -l \n",
    "COUNT_KURABE_ADNOMINAL = int(COUNT_KURABE_ADNOMINAL)\n",
    "\n",
    "# そもそも比較構文でない物の数\n",
    "COUNT_KURABE_NA, *_ = ! cat /tmp/comp-kurabe.psd | sed -e '/#comp/d' | wc -l\n",
    "COUNT_KURABE_NA = int(COUNT_KURABE_NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集計\n",
    "import pandas as pd\n",
    "\n",
    "STAT = pd.DataFrame(\n",
    "    {\n",
    "        \"全文数\": [COUNT_YORI, COUNT_KURABE],\n",
    "        \"連用節数\": [COUNT_YORI_ADVERBIAL, COUNT_KURABE_ADVERBIAL],\n",
    "        \"連体節数\": [COUNT_YORI_ADNOMINAL, COUNT_KURABE_ADNOMINAL],\n",
    "        \"その他比較構文数\": [\n",
    "            COUNT_YORI - COUNT_YORI_ADVERBIAL - COUNT_YORI_ADNOMINAL - COUNT_YORI_NA,\n",
    "            COUNT_KURABE - COUNT_KURABE_ADVERBIAL - COUNT_KURABE_ADNOMINAL - COUNT_KURABE_NA,\n",
    "        ],\n",
    "        \"比較構文でない数\": [COUNT_YORI_NA, COUNT_KURABE_NA],\n",
    "    },\n",
    "    index = [\"より\", \"比べて\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>全文数</th>\n",
       "      <th>連用節数</th>\n",
       "      <th>連体節数</th>\n",
       "      <th>その他比較構文数</th>\n",
       "      <th>比較構文でない数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>より</th>\n",
       "      <td>2700</td>\n",
       "      <td>288</td>\n",
       "      <td>449</td>\n",
       "      <td>1108</td>\n",
       "      <td>855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>比べて</th>\n",
       "      <td>1042</td>\n",
       "      <td>123</td>\n",
       "      <td>89</td>\n",
       "      <td>552</td>\n",
       "      <td>278</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      全文数  連用節数  連体節数  その他比較構文数  比較構文でない数\n",
       "より   2700   288   449      1108       855\n",
       "比べて  1042   123    89       552       278"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "全文数         3742\n",
       "連用節数         411\n",
       "連体節数         538\n",
       "その他比較構文数    1660\n",
       "比較構文でない数    1133\n",
       "dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合計\n",
    "STAT.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データ／評価データ\n",
    "9:1になるように，事前に分割した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration abctreebank--comparative-NER-BCCWJ-f36bf31580d9adae\n",
      "Reusing dataset parquet (/home/owner/.cache/huggingface/datasets/abctreebank___parquet/abctreebank--comparative-NER-BCCWJ-f36bf31580d9adae/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 2/2 [00:00<00:00, 321.17it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'tokens', 'comp'],\n",
       "        num_rows: 374\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'tokens', 'comp'],\n",
       "        num_rows: 3368\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# NOTE: private repoなので，事前にログインが必要。\n",
    "ds = datasets.load_dataset(\n",
    "    \"abctreebank/comparative-NER-BCCWJ\",\n",
    "    use_auth_token = True,\n",
    ")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 学習データ数： 3,368文\n",
    "* テストデータ数： 374文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データの例\n",
    "\n",
    "#### 単文\n",
    "```\n",
    "5_BCCWJ-ABC-aa-simple\n",
    "妻 が 仕事 に 精出す 一方 、 [[赤沼 は]cont [それ より]prej [もっと]diff [忙しい]deg 。]root\n",
    "\n",
    "5_BCCWJ-ABC-aa-simple_predicted\n",
    "[CLS] 妻 が 仕事 に 精 ##出す 一方 、 [赤 ##沼 は]cont [それ より]prej [もっと]diff [忙 ##しい]deg 。 [SEP]\n",
    "\n",
    "\n",
    "95_bccwj_kurabe_text-aj-simplified\n",
    "[[旧法 が 成立 し た 当時 に 比べ て]prej 、 私 たち の 食生活 は [格段 に]diff [豊か]deg に なっ た 。]root\n",
    "\n",
    "95_bccwj_kurabe_text-aj-simplified_predicted\n",
    "[CLS] [旧 ##法 が 成立 し た 当時 に 比べ て]prej 、 私 たち の 食 ##生活 は [格段 に]diff [豊か]deg に なっ た 。 [SEP]\n",
    "\n",
    "35_bccwj_kurabe_text-ah-simplified\n",
    "[[アカ ナマコ の 成長 は]cont [アオナマコ に]prej [比べ]prej [若干]diff [劣っ]deg て い た 。]root\n",
    "\n",
    "35_bccwj_kurabe_text-ah-simplified_predicted\n",
    "[CLS] [アカ ナ ##マコ の]cont 成長 は [アオ ##ナ ##マコ に 比べ]prej [若干]diff [劣っ]deg て い た 。 [SEP]\n",
    "```\n",
    "\n",
    "#### 連用節\n",
    "```\n",
    "23_bccwj_kurabe_text-af-simplified\n",
    "ところが 、 一 九 八 五 年 九月 の プラザ 合意 以降 、 [[円 が]cont [ドル に 比べ て]prej [百 ％ 以上]diff [はね上がり]deg]root 、 突然 日本 は アメリカ より はるか に 高 コスト の 国 に なり まし た 。\n",
    "\n",
    "23_bccwj_kurabe_text-af-simplified_predicted\n",
    "[CLS] ところが 、 一 九 八 五 年 九 ##月 の プラザ 合意 以降 、 [円 が]cont [ドル に 比べ て]prej [百 % 以上]diff [はね ##上がり]deg 、 突然 [日本 は]cont [アメリカ より]prej [はるか に]diff [高 コスト]deg の 国 に なり まし た 。 [SEP]\n",
    "```\n",
    "\n",
    "#### 連体節\n",
    "```\n",
    "21_BCCWJ-ABC-as-simple\n",
    "三 十 歳 の サラリーマン が [自分 より]prej [七]diff [、]diff [[[八 歳]diff [年下]deg]cont]root の 「 新入 社員 の 気持ち が わから ない 」 と 言っ て いる 。\n",
    "\n",
    "21_BCCWJ-ABC-as-simple_predicted\n",
    "[CLS] 三 十 歳 の サラリーマン [が]cont [自分 より]prej [七 、 八 歳]diff [年下]deg の 「 新入 社員 の 気持ち が わから ない 」 と 言っ て いる 。 [SEP]\n",
    "```\n",
    "（ `[が]cont` が変）\n",
    "\n",
    "```\n",
    "99_BCCWJ-ABC-au-simple\n",
    "何 畳 ある か わから ない くらい 、 [[[教室 より も]prej [広い]deg]cont]root 部屋 。\n",
    "\n",
    "99_BCCWJ-ABC-au-simple_predicted\n",
    "[CLS] 何 畳 ある か わから ない くらい 、 [教室 より も]prej [広い]deg 部屋 。 [SEP]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの設定\n",
    "* 使用した事前学習モデル： https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking\n",
    "* このモデルの上で，NER（固有表現認識）の一種として，与えられた文のどのspanが，比較構文の要素に相当するのかについてのモデルを構築。\n",
    "* 比較構文の要素：\n",
    "    * prej(acent)：「より」句\n",
    "    * cont(rast)：比較対象\n",
    "    * diff(erence)：差の表現\n",
    "    * deg(ree)：程度表現\n",
    "    * root：比較構文の最大スコープ（NERモデルにおいては取り除いた）\n",
    "* 例： [ [太郎が]cont [花子よりも]prej [3cm]diff [高い]deg ]root ことは意外だった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習パラメータ\n",
    "\n",
    "training_args = dict(\n",
    "    # output_dir = str(output_path),\n",
    "\n",
    "    # エポック数\n",
    "    num_train_epochs = 27,\n",
    "\n",
    "    # バッチのサイズ\n",
    "    per_device_train_batch_size = 64,\n",
    "    per_device_eval_batch_size = 128,\n",
    "\n",
    "    # 学習率\n",
    "    learning_rate = 5e-5,\n",
    "    \n",
    "    warmup_steps = 200,\n",
    "    weight_decay = 0,\n",
    "    # save_strategy = IntervalStrategy.STEPS,\n",
    "    save_steps = 1000,\n",
    "    do_eval = True,\n",
    "    # evaluation_strategy = IntervalStrategy.STEPS,\n",
    "    eval_steps = 109,\n",
    "    include_inputs_for_metrics = True,\n",
    "\n",
    "    # 乱数シード\n",
    "    seed = 2630987289,\n",
    "\n",
    "    # logging_dir = str(output_path / \"logs\"),\n",
    "    logging_steps= 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\"score_spanwise_details\": {\"cont\": {\"CORRECT\": 107, \"WRONG_SPAN\": 73, \"SPURIOUS\": 67, \"MISSING\": 53, \"WRONG_LABEL\": 1, \"WRONG_LABEL_SPAN\": 9}, \"prej\": {\"CORRECT\": 229, \"WRONG_LABEL_SPAN\": 6, \"WRONG_SPAN\": 33, \"MISSING\": 5, \"SPURIOUS\": 32}, \"diff\": {\"CORRECT\": 63, \"MISSING\": 10, \"SPURIOUS\": 14, \"WRONG_SPAN\": 10, \"WRONG_LABEL_SPAN\": 1}, \"deg\": {\"CORRECT\": 218, \"WRONG_SPAN\": 15, \"WRONG_LABEL\": 3, \"SPURIOUS\": 60, \"MISSING\": 34, \"WRONG_LABEL_SPAN\": 4}}, \"score_spanwise\": {\"cont\": {\"possible_entries\": 243, \"actual_entries\": 257, \"precision_strict\": 0.4163424124513619, \"recall_strict\": 0.4403292181069959, \"F1_strict\": 0.574, \"precision_partial\": 0.5583657587548638, \"recall_partial\": 0.5905349794238683}, \"prej\": {\"possible_entries\": 273, \"actual_entries\": 300, \"precision_strict\": 0.7633333333333333, \"recall_strict\": 0.8388278388278388, \"F1_strict\": 0.8568935427574172, \"precision_partial\": 0.8183333333333334, \"recall_partial\": 0.8992673992673993}, \"diff\": {\"possible_entries\": 84, \"actual_entries\": 88, \"precision_strict\": 0.7159090909090909, \"recall_strict\": 0.75, \"F1_strict\": 0.7906976744186046, \"precision_partial\": 0.7727272727272727, \"recall_partial\": 0.8095238095238095}, \"deg\": {\"possible_entries\": 274, \"actual_entries\": 300, \"precision_strict\": 0.7266666666666667, \"recall_strict\": 0.7956204379562044, \"F1_strict\": 0.7857142857142858, \"precision_partial\": 0.7516666666666667, \"recall_partial\": 0.822992700729927}}, \"score_spanwise_F1_strict\": 0.7518263757225769, \"score_tokenwise\": {\"IGNORE\": {\"precision\": 0.0, \"recall\": 0.0, \"f1-score\": 0.0, \"support\": 0}, \"O\": {\"precision\": 0.9349922839506173, \"recall\": 0.9109190001879346, \"f1-score\": 0.9227986673012851, \"support\": 5321}, \"B-deg\": {\"precision\": 0.761437908496732, \"recall\": 0.8411552346570397, \"f1-score\": 0.7993138936535162, \"support\": 277}, \"B-prej\": {\"precision\": 0.8160535117056856, \"recall\": 0.8591549295774648, \"f1-score\": 0.83704974271012, \"support\": 284}, \"B-cont\": {\"precision\": 0.6639004149377593, \"recall\": 0.6986899563318777, \"f1-score\": 0.6808510638297872, \"support\": 229}, \"B-diff\": {\"precision\": 0.7419354838709677, \"recall\": 0.7752808988764045, \"f1-score\": 0.7582417582417582, \"support\": 89}, \"I-deg\": {\"precision\": 0.6923076923076923, \"recall\": 0.7397260273972602, \"f1-score\": 0.7152317880794701, \"support\": 73}, \"I-prej\": {\"precision\": 0.8496, \"recall\": 0.959349593495935, \"f1-score\": 0.9011455239711498, \"support\": 1107}, \"I-cont\": {\"precision\": 0.7381703470031545, \"recall\": 0.6733812949640288, \"f1-score\": 0.7042889390519188, \"support\": 695}, \"I-diff\": {\"precision\": 0.7654320987654321, \"recall\": 0.6813186813186813, \"f1-score\": 0.7209302325581395, \"support\": 91}, \"micro avg\": {\"precision\": 0.881582169973059, \"recall\": 0.881582169973059, \"f1-score\": 0.881582169973059, \"support\": 8166}, \"macro avg\": {\"precision\": 0.6963829741038041, \"recall\": 0.7138975616806627, \"f1-score\": 0.7039851609397145, \"support\": 8166}, \"weighted avg\": {\"precision\": 0.8828759818341678, \"recall\": 0.881582169973059, \"f1-score\": 0.8814116671139006, \"support\": 8166}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORRECT</th>\n",
       "      <th>WRONG_SPAN</th>\n",
       "      <th>SPURIOUS</th>\n",
       "      <th>MISSING</th>\n",
       "      <th>WRONG_LABEL</th>\n",
       "      <th>WRONG_LABEL_SPAN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>107</td>\n",
       "      <td>73</td>\n",
       "      <td>67</td>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>229</td>\n",
       "      <td>33</td>\n",
       "      <td>32</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>63</td>\n",
       "      <td>10</td>\n",
       "      <td>14</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>218</td>\n",
       "      <td>15</td>\n",
       "      <td>60</td>\n",
       "      <td>34</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CORRECT  WRONG_SPAN  SPURIOUS  MISSING  WRONG_LABEL  WRONG_LABEL_SPAN\n",
       "cont      107          73        67       53          1.0                 9\n",
       "prej      229          33        32        5          NaN                 6\n",
       "diff       63          10        14       10          NaN                 1\n",
       "deg       218          15        60       34          3.0                 4"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データカウント\n",
    "df_res_count = pd.DataFrame.from_dict(\n",
    "    result[\"score_spanwise_details\"],\n",
    "    orient = \"index\",\n",
    ")\n",
    "\n",
    "df_res_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CORRECT: ぴったり\n",
    "* WRONG_SPAN: spanにずれがある。\n",
    "* SPURIOUS: 正解データにないspanを予測してしまっている。\n",
    "* MISSING: 正解データにあるspanを予測できていない。\n",
    "* WRONG_LABEL_SPAN: spanにずれがあり，かつ，ラベルも間違っている。\n",
    "* WRONG_LABEL: spanにずれはないが，ラベルが間違っている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>possible_entries</th>\n",
       "      <th>actual_entries</th>\n",
       "      <th>precision_strict</th>\n",
       "      <th>recall_strict</th>\n",
       "      <th>F1_strict</th>\n",
       "      <th>precision_partial</th>\n",
       "      <th>recall_partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>243</td>\n",
       "      <td>257</td>\n",
       "      <td>0.416342</td>\n",
       "      <td>0.440329</td>\n",
       "      <td>0.574000</td>\n",
       "      <td>0.558366</td>\n",
       "      <td>0.590535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>273</td>\n",
       "      <td>300</td>\n",
       "      <td>0.763333</td>\n",
       "      <td>0.838828</td>\n",
       "      <td>0.856894</td>\n",
       "      <td>0.818333</td>\n",
       "      <td>0.899267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>84</td>\n",
       "      <td>88</td>\n",
       "      <td>0.715909</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.790698</td>\n",
       "      <td>0.772727</td>\n",
       "      <td>0.809524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>274</td>\n",
       "      <td>300</td>\n",
       "      <td>0.726667</td>\n",
       "      <td>0.795620</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.751667</td>\n",
       "      <td>0.822993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      possible_entries  actual_entries  precision_strict  recall_strict  \\\n",
       "cont               243             257          0.416342       0.440329   \n",
       "prej               273             300          0.763333       0.838828   \n",
       "diff                84              88          0.715909       0.750000   \n",
       "deg                274             300          0.726667       0.795620   \n",
       "\n",
       "      F1_strict  precision_partial  recall_partial  \n",
       "cont   0.574000           0.558366        0.590535  \n",
       "prej   0.856894           0.818333        0.899267  \n",
       "diff   0.790698           0.772727        0.809524  \n",
       "deg    0.785714           0.751667        0.822993  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 統計\n",
    "df_res_stat = pd.DataFrame.from_dict(\n",
    "    result[\"score_spanwise\"],\n",
    "    orient = \"index\",\n",
    ")\n",
    "\n",
    "df_res_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 凡例\n",
    "\n",
    "* `possible_entries`: 予測されたspanの数\n",
    "    ```\n",
    "    ct[\"CORRECT\"] + ct[\"WRONG_SPAN\"] + ct[\"WRONG_LABEL\"] + ct[\"WRONG_LABEL_SPAN\"] + ct[\"MISSING\"]\n",
    "    ```\n",
    "* `actual_entires`: テストデータにあるspanの数\n",
    "    ```\n",
    "    res[\"possible_entries\"] - ct[\"MISSING\"] + ct[\"SPURIOUS\"]\n",
    "    ```\n",
    "* `precision_strict`: 予測のうち，当たっているものの数\n",
    "    ```\n",
    "    ct[\"CORRECT\"] / res[\"actual_entries\"]\n",
    "    ```\n",
    "* `recall_strict`: テストデータにあるもののうち，予測されたspanの数\n",
    "    ```\n",
    "    ct[\"CORRECT\"] / res[\"possible_entries\"]\n",
    "    ```\n",
    "* `precision_partial`：strictよりも緩い。 WRONG_SPANを50%カウントに入れている。\n",
    "    ```\n",
    "    (ct[\"CORRECT\"] + 0.5 * ct[\"WRONG_SPAN\"]) / res[\"actual_entries\"]\n",
    "    ```\n",
    "* `recall_partial`\n",
    "    ```\n",
    "    (ct[\"CORRECT\"] + 0.5 * ct[\"WRONG_SPAN\"]) / res[\"possible_entries\"]\n",
    "    ```\n",
    "* F1はprecisionとrecallの調和平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7518263757225769"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1_strictの単純平均。ラベルのカウントで重みづけることはしていない。\n",
    "result[\"score_spanwise_F1_strict\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習結果：連体節なしバージョン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まず，連体節に該当する文のIDを抜き出す。\n",
    "\n",
    "TREES_YORI_ADNOMINAL =  ! tregex -s -w '/^(VPrel|Srel|N)/ == /root/' /tmp/comp-yori.psd 2> /dev/null | sort | uniq\n",
    "TREES_KURABE_ADNOMINAL =  ! tregex -s -w '/^(VPrel|Srel|N)/ == /root/' /tmp/comp-kurabe.psd 2> /dev/null | sort | uniq\n",
    "\n",
    "TREES_ADNOMINAL = TREES_YORI_ADNOMINAL + TREES_KURABE_ADNOMINAL\n",
    "\n",
    "import re\n",
    "_RE_TREE_ID = re.compile(r\"\\(ID (?P<ID>[^)]+)\\)\")\n",
    "IDs_ADNOMINAL = [\n",
    "    # tree.group(\"ID\")\n",
    "    tree.group(\"ID\")\n",
    "    for tree in \n",
    "    filter(None, map(_RE_TREE_ID.search, TREES_ADNOMINAL))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration abctreebank--comparative-NER-BCCWJ-f36bf31580d9adae\n",
      "Reusing dataset parquet (/home/owner/.cache/huggingface/datasets/abctreebank___parquet/abctreebank--comparative-NER-BCCWJ-f36bf31580d9adae/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 1/1 [00:00<00:00, 19.33ba/s]\n",
      "100%|██████████| 323/323 [00:04<00:00, 68.01ex/s] \n",
      "100%|██████████| 3/3 [00:18<00:00,  6.29s/ba]\n"
     ]
    }
   ],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "import datasets\n",
    "from transformers import BertConfig, BertForTokenClassification, BertJapaneseTokenizer, EvalPrediction, IntervalStrategy, TokenClassificationPipeline, Trainer, TrainingArguments\n",
    "import evaluate\n",
    "\n",
    "from abct_comp_ner_utils.train import _add_vectors, ID2LABEL_DETAILED, LABEL2ID, _get_tokenizer, _get_evaluator\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\"../results_2022-10-19\")\n",
    "\n",
    "assert(isinstance(model, BertForTokenClassification))\n",
    "\n",
    "dataset = datasets.load_dataset(\n",
    "    \"abctreebank/comparative-NER-BCCWJ\",\n",
    "    use_auth_token = True,\n",
    "    split = \"test\",\n",
    ")\n",
    "assert(isinstance(dataset, datasets.Dataset))\n",
    "\n",
    "# 連体節を排除\n",
    "dataset = dataset.filter(\n",
    "    lambda x: x[\"ID\"] not in IDs_ADNOMINAL\n",
    ")\n",
    "\n",
    "dataset = dataset.map(\n",
    "    _add_vectors,\n",
    ")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def _make_spans(\n",
    "    input: Sequence | np.ndarray,\n",
    "    pred: Sequence | np.ndarray\n",
    "):\n",
    "    result = {\n",
    "        \"start\": [],\n",
    "        \"end\": [],\n",
    "        \"label\": [],\n",
    "    }\n",
    "\n",
    "    current_label = ID2LABEL_DETAILED[0][0]\n",
    "    current_span_start: int = 0\n",
    "\n",
    "    for loc, (input_id, label_id) in enumerate(zip(input, pred)):\n",
    "        label = ID2LABEL_DETAILED[label_id][0]\n",
    "\n",
    "        if input_id == 0:\n",
    "            # reached padding\n",
    "            break\n",
    "        elif current_label != label:\n",
    "            # label changed\n",
    "            # conclude the old label\n",
    "            if current_label not in (\"IGNORE\", \"O\"):\n",
    "                result[\"start\"].append(current_span_start)\n",
    "                result[\"end\"].append(loc)\n",
    "                result[\"label\"].append(current_label)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            # switch to new label\n",
    "            current_label = label\n",
    "            current_span_start = loc\n",
    "\n",
    "    return result\n",
    "\n",
    "def _decode(tokens):\n",
    "    tokens_decoded = _get_tokenizer().batch_decode(\n",
    "        [t for t in tokens if t != 0],\n",
    "        skip_special_tokens = True,\n",
    "    )\n",
    "\n",
    "    return [t.replace(\" \", \"\") for t in tokens_decoded]\n",
    "\n",
    "def _predict(\n",
    "    examples: datasets.arrow_dataset.Example | datasets.arrow_dataset.Batch\n",
    "):\n",
    "    examples[\"tokens_re\"] = [\n",
    "        _decode(entry) for entry in examples[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    predictions_raw = model.forward(\n",
    "        input_ids = torch.tensor(examples[\"input_ids\"]),\n",
    "        attention_mask = torch.tensor(examples[\"attention_mask\"]),\n",
    "        token_type_ids = torch.tensor(examples[\"token_type_ids\"]),\n",
    "    ).logits\n",
    "    match predictions_raw:\n",
    "        case torch.Tensor():\n",
    "            predictions: np.ndarray = predictions_raw.argmax(dim = 2).numpy()\n",
    "        case np.ndarray():\n",
    "            predictions: np.ndarray = predictions_raw.argmax(axis = 2)\n",
    "        case _:\n",
    "            raise TypeError\n",
    "    examples[\"prediction\"] = predictions\n",
    "\n",
    "\n",
    "    examples[\"comp_predicted\"] = [\n",
    "        _make_spans(i, p)\n",
    "        for i, p in zip(examples[\"input_ids\"], predictions)\n",
    "    ]\n",
    "    \n",
    "    return examples\n",
    "\n",
    "dataset = dataset.map(\n",
    "    _predict,\n",
    "    batched = True,\n",
    "    batch_size = 128,\n",
    ")\n",
    "\n",
    "_eval: evaluate.Metric = _get_evaluator(\n",
    "    \"../comparative-NER-metrics\"\n",
    ")\n",
    "\n",
    "res_no_adnom = _eval._compute(\n",
    "    predictions = dataset[\"prediction\"],\n",
    "    references = dataset[\"label_ids\"],\n",
    "    input_ids = dataset[\"input_ids\"],\n",
    "    special_ids = _get_tokenizer().all_special_ids,\n",
    "    label2id = LABEL2ID,\n",
    "    id2label_detailed = ID2LABEL_DETAILED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORRECT</th>\n",
       "      <th>WRONG_SPAN</th>\n",
       "      <th>SPURIOUS</th>\n",
       "      <th>MISSING</th>\n",
       "      <th>WRONG_LABEL_SPAN</th>\n",
       "      <th>WRONG_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>87</td>\n",
       "      <td>64</td>\n",
       "      <td>52</td>\n",
       "      <td>35</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>188</td>\n",
       "      <td>25</td>\n",
       "      <td>31</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>47</td>\n",
       "      <td>7</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>180</td>\n",
       "      <td>11</td>\n",
       "      <td>54</td>\n",
       "      <td>28</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CORRECT  WRONG_SPAN  SPURIOUS  MISSING  WRONG_LABEL_SPAN  WRONG_LABEL\n",
       "cont       87          64        52       35                 5          NaN\n",
       "prej      188          25        31        3                 6          NaN\n",
       "diff       47           7        12        9                 1          NaN\n",
       "deg       180          11        54       28                 4          2.0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データカウント\n",
    "df_res_count_no_adnom = pd.DataFrame.from_dict(\n",
    "    res_no_adnom[\"score_spanwise_details\"],\n",
    "    orient = \"index\",\n",
    ")\n",
    "\n",
    "df_res_count_no_adnom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>possible_entries</th>\n",
       "      <th>actual_entries</th>\n",
       "      <th>precision_strict</th>\n",
       "      <th>recall_strict</th>\n",
       "      <th>F1_strict</th>\n",
       "      <th>precision_partial</th>\n",
       "      <th>recall_partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>191</td>\n",
       "      <td>208</td>\n",
       "      <td>0.418269</td>\n",
       "      <td>0.455497</td>\n",
       "      <td>0.596491</td>\n",
       "      <td>0.572115</td>\n",
       "      <td>0.623037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>222</td>\n",
       "      <td>250</td>\n",
       "      <td>0.752000</td>\n",
       "      <td>0.846847</td>\n",
       "      <td>0.849576</td>\n",
       "      <td>0.802000</td>\n",
       "      <td>0.903153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>64</td>\n",
       "      <td>67</td>\n",
       "      <td>0.701493</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.770992</td>\n",
       "      <td>0.753731</td>\n",
       "      <td>0.789062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>225</td>\n",
       "      <td>251</td>\n",
       "      <td>0.717131</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.779412</td>\n",
       "      <td>0.739044</td>\n",
       "      <td>0.824444</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      possible_entries  actual_entries  precision_strict  recall_strict  \\\n",
       "cont               191             208          0.418269       0.455497   \n",
       "prej               222             250          0.752000       0.846847   \n",
       "diff                64              67          0.701493       0.734375   \n",
       "deg                225             251          0.717131       0.800000   \n",
       "\n",
       "      F1_strict  precision_partial  recall_partial  \n",
       "cont   0.596491           0.572115        0.623037  \n",
       "prej   0.849576           0.802000        0.903153  \n",
       "diff   0.770992           0.753731        0.789062  \n",
       "deg    0.779412           0.739044        0.824444  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res_stat_no_adnom = pd.DataFrame.from_dict(\n",
    "    res_no_adnom[\"score_spanwise\"],\n",
    "    orient = \"index\",\n",
    ")\n",
    "\n",
    "df_res_stat_no_adnom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.749117907593678"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1_strictの単純平均。ラベルのカウントで重みづけることはしていない。\n",
    "res_no_adnom[\"score_spanwise_F1_strict\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('comparative-ner-utils-sv0RmVnD-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98ff88495b25d3c68e7ba2c5383ef33c76229d3a0872ace53e941ddd39c21b36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
