{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 報告 2022-09-02\n",
    "\n",
    "## 元データの内訳"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "vscode": {
     "languageId": "shellscript"
    }
   },
   "outputs": [],
   "source": [
    "%%sh\n",
    "cat ~/ABCT/comp-proto/Annotation-complete-IDed/BCCWJ-ABC*.psd | munge-trees -w > /tmp/comp-yori.psd\n",
    "cat ~/ABCT/comp-proto/Annotation-complete-IDed/bccwj_kurabe_*.psd | munge-trees -w > /tmp/comp-kurabe.psd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「より」の文数\n",
    "COUNT_YORI, *_ = ! cat /tmp/comp-yori.psd | wc -l\n",
    "COUNT_YORI = int(COUNT_YORI)\n",
    "\n",
    "# 「より」のうち，単文の数\n",
    "# NOTE: CPに関しては，全て単文であることを目視済み。\n",
    "# NOTE: tregex options: -s: one-liner, -w: whole tree\n",
    "COUNT_YORI_SIMPLE, *_ = ! tregex -s -w '/^(VPm|VPsub|Sm|Ssub|CP)/ == /root/' /tmp/comp-yori.psd 2> /dev/null | sort | uniq | wc -l \n",
    "COUNT_YORI_SIMPLE = int(COUNT_YORI_SIMPLE)\n",
    "\n",
    "# 「より」のうち，連用節の数\n",
    "COUNT_YORI_ADVERBIAL, *_ = ! tregex -s -w '/^(VPa|Sa)/ == /root/' /tmp/comp-yori.psd 2> /dev/null | sort | uniq | wc -l \n",
    "COUNT_YORI_ADVERBIAL = int(COUNT_YORI_ADVERBIAL)\n",
    "\n",
    "# 「より」のうち，連体節の数\n",
    "COUNT_YORI_ADNOMINAL, *_ =  ! tregex -s -w '/^(VPrel|Srel|N)/ == /root/' /tmp/comp-yori.psd 2> /dev/null | sort | uniq | wc -l \n",
    "COUNT_YORI_ADNOMINAL = int(COUNT_YORI_ADNOMINAL)\n",
    "\n",
    "# そもそも比較構文でない物の数\n",
    "COUNT_YORI_NA, *_ = ! cat /tmp/comp-yori.psd | sed -e '/#comp/d' | wc -l\n",
    "COUNT_YORI_NA = int(COUNT_YORI_NA)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 「比べて」の文数\n",
    "COUNT_KURABE, *_ = ! cat /tmp/comp-kurabe.psd | wc -l\n",
    "COUNT_KURABE = int(COUNT_KURABE)\n",
    "\n",
    "# 「比べて」のうち，単文の数\n",
    "# NOTE: CPに関しては，全て単文であることを目視済み。\n",
    "# NOTE: tregex options: -s: one-liner, -w: whole tree\n",
    "COUNT_KURABE_SIMPLE, *_ = ! tregex -s -w '/^(VPm|VPsub|Sm|Ssub|CP)/ == /root/' /tmp/comp-kurabe.psd 2> /dev/null | sort | uniq | wc -l \n",
    "COUNT_KURABE_SIMPLE = int(COUNT_KURABE_SIMPLE)\n",
    "\n",
    "# 「比べて」のうち，連用節の数\n",
    "COUNT_KURABE_ADVERBIAL, *_ = ! tregex -s -w '/^(VPa|Sa)/ == /root/' /tmp/comp-kurabe.psd 2> /dev/null | sort | uniq | wc -l \n",
    "COUNT_KURABE_ADVERBIAL = int(COUNT_KURABE_ADVERBIAL)\n",
    "\n",
    "# 「比べて」のうち，連体節の数\n",
    "COUNT_KURABE_ADNOMINAL, *_ =  ! tregex -s -w '/^(VPrel|Srel|N)/ == /root/' /tmp/comp-kurabe.psd 2> /dev/null | sort | uniq | wc -l \n",
    "COUNT_KURABE_ADNOMINAL = int(COUNT_KURABE_ADNOMINAL)\n",
    "\n",
    "# そもそも比較構文でない物の数\n",
    "COUNT_KURABE_NA, *_ = ! cat /tmp/comp-kurabe.psd | sed -e '/#comp/d' | wc -l\n",
    "COUNT_KURABE_NA = int(COUNT_KURABE_NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 集計\n",
    "import pandas as pd\n",
    "\n",
    "STAT = pd.DataFrame(\n",
    "    {\n",
    "        \"全文数\": [COUNT_YORI, COUNT_KURABE],\n",
    "        \"連用節数\": [COUNT_YORI_ADVERBIAL, COUNT_KURABE_ADVERBIAL],\n",
    "        \"連体節数\": [COUNT_YORI_ADNOMINAL, COUNT_KURABE_ADNOMINAL],\n",
    "        \"その他比較構文数\": [\n",
    "            COUNT_YORI - COUNT_YORI_ADVERBIAL - COUNT_YORI_ADNOMINAL - COUNT_YORI_NA,\n",
    "            COUNT_KURABE - COUNT_KURABE_ADVERBIAL - COUNT_KURABE_ADNOMINAL - COUNT_KURABE_NA,\n",
    "        ],\n",
    "        \"比較構文でない数\": [COUNT_YORI_NA, COUNT_KURABE_NA],\n",
    "    },\n",
    "    index = [\"より\", \"比べて\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>全文数</th>\n",
       "      <th>連用節数</th>\n",
       "      <th>連体節数</th>\n",
       "      <th>その他比較構文数</th>\n",
       "      <th>比較構文でない数</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>より</th>\n",
       "      <td>2700</td>\n",
       "      <td>292</td>\n",
       "      <td>449</td>\n",
       "      <td>1112</td>\n",
       "      <td>847</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>比べて</th>\n",
       "      <td>1042</td>\n",
       "      <td>123</td>\n",
       "      <td>87</td>\n",
       "      <td>580</td>\n",
       "      <td>252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      全文数  連用節数  連体節数  その他比較構文数  比較構文でない数\n",
       "より   2700   292   449      1112       847\n",
       "比べて  1042   123    87       580       252"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "全文数         3742\n",
       "連用節数         415\n",
       "連体節数         536\n",
       "その他比較構文数    1692\n",
       "比較構文でない数    1099\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 合計\n",
    "STAT.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習データ／評価データ\n",
    "9:1になるように，事前に分割した。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration abctreebank--comparative-NER-BCCWJ-fe0cb4ac0d530735\n",
      "Reusing dataset parquet (/home/owner/.cache/huggingface/datasets/abctreebank___parquet/abctreebank--comparative-NER-BCCWJ-fe0cb4ac0d530735/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "100%|██████████| 2/2 [00:00<00:00, 252.26it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'tokens', 'comp'],\n",
       "        num_rows: 3368\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'tokens', 'comp'],\n",
       "        num_rows: 374\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datasets\n",
    "\n",
    "# NOTE: private repoなので，事前にログインが必要。\n",
    "ds = datasets.load_dataset(\n",
    "    \"abctreebank/comparative-NER-BCCWJ\",\n",
    "    revision = \"3846bb0dc229dcfa07857ed1ab8aa55d94066882\",\n",
    "    use_auth_token = True,\n",
    ")\n",
    "\n",
    "ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 学習データ数： 3,368文\n",
    "* テストデータ数： 374文"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習データの例\n",
    "\n",
    "#### 単文\n",
    "```\n",
    "5_BCCWJ-ABC-aa-simple\n",
    "妻 が 仕事 に 精出す 一方 、 [[赤沼 は]cont [それ より]prej [もっと]diff [忙しい]deg 。]root\n",
    "\n",
    "5_BCCWJ-ABC-aa-simple_predicted\n",
    "[CLS] 妻 が 仕事 に 精 ##出す 一方 、 [赤 ##沼 は]cont [それ より]prej [もっと]diff [忙 ##しい]deg 。 [SEP]\n",
    "\n",
    "\n",
    "95_bccwj_kurabe_text-aj-simplified\n",
    "[[旧法 が 成立 し た 当時 に 比べ て]prej 、 私 たち の 食生活 は [格段 に]diff [豊か]deg に なっ た 。]root\n",
    "\n",
    "95_bccwj_kurabe_text-aj-simplified_predicted\n",
    "[CLS] [旧 ##法 が 成立 し た 当時 に 比べ て]prej 、 私 たち の 食 ##生活 は [格段 に]diff [豊か]deg に なっ た 。 [SEP]\n",
    "\n",
    "35_bccwj_kurabe_text-ah-simplified\n",
    "[[アカ ナマコ の 成長 は]cont [アオナマコ に]prej [比べ]prej [若干]diff [劣っ]deg て い た 。]root\n",
    "\n",
    "35_bccwj_kurabe_text-ah-simplified_predicted\n",
    "[CLS] [アカ ナ ##マコ の]cont 成長 は [アオ ##ナ ##マコ に 比べ]prej [若干]diff [劣っ]deg て い た 。 [SEP]\n",
    "```\n",
    "\n",
    "#### 連用節\n",
    "```\n",
    "23_bccwj_kurabe_text-af-simplified\n",
    "ところが 、 一 九 八 五 年 九月 の プラザ 合意 以降 、 [[円 が]cont [ドル に 比べ て]prej [百 ％ 以上]diff [はね上がり]deg]root 、 突然 日本 は アメリカ より はるか に 高 コスト の 国 に なり まし た 。\n",
    "\n",
    "23_bccwj_kurabe_text-af-simplified_predicted\n",
    "[CLS] ところが 、 一 九 八 五 年 九 ##月 の プラザ 合意 以降 、 [円 が]cont [ドル に 比べ て]prej [百 % 以上]diff [はね ##上がり]deg 、 突然 [日本 は]cont [アメリカ より]prej [はるか に]diff [高 コスト]deg の 国 に なり まし た 。 [SEP]\n",
    "```\n",
    "\n",
    "#### 連体節\n",
    "```\n",
    "21_BCCWJ-ABC-as-simple\n",
    "三 十 歳 の サラリーマン が [自分 より]prej [七]diff [、]diff [[[八 歳]diff [年下]deg]cont]root の 「 新入 社員 の 気持ち が わから ない 」 と 言っ て いる 。\n",
    "\n",
    "21_BCCWJ-ABC-as-simple_predicted\n",
    "[CLS] 三 十 歳 の サラリーマン [が]cont [自分 より]prej [七 、 八 歳]diff [年下]deg の 「 新入 社員 の 気持ち が わから ない 」 と 言っ て いる 。 [SEP]\n",
    "```\n",
    "（ `[が]cont` が変）\n",
    "\n",
    "```\n",
    "99_BCCWJ-ABC-au-simple\n",
    "何 畳 ある か わから ない くらい 、 [[[教室 より も]prej [広い]deg]cont]root 部屋 。\n",
    "\n",
    "99_BCCWJ-ABC-au-simple_predicted\n",
    "[CLS] 何 畳 ある か わから ない くらい 、 [教室 より も]prej [広い]deg 部屋 。 [SEP]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## モデルの設定\n",
    "* 使用した事前学習モデル： https://huggingface.co/cl-tohoku/bert-base-japanese-whole-word-masking\n",
    "* このモデルの上で，NER（固有表現認識）の一種として，与えられた文のどのspanが，比較構文の要素に相当するのかについてのモデルを構築。\n",
    "* 比較構文の要素：\n",
    "    * prej(acent)：「より」句\n",
    "    * cont(rast)：比較対象\n",
    "    * diff(erence)：差の表現\n",
    "    * deg(ree)：程度表現\n",
    "    * root：比較構文の最大スコープ（NERモデルにおいては取り除いた）\n",
    "* 例： [ [太郎が]cont [花子よりも]prej [3cm]diff [高い]deg ]root ことは意外だった。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習パラメータ\n",
    "\n",
    "training_args = dict(\n",
    "    # output_dir = str(output_path),\n",
    "\n",
    "    # エポック数\n",
    "    num_train_epochs = 27,\n",
    "\n",
    "    # バッチのサイズ\n",
    "    per_device_train_batch_size = 64,\n",
    "    per_device_eval_batch_size = 128,\n",
    "\n",
    "    # 学習率\n",
    "    learning_rate = 5e-5,\n",
    "    \n",
    "    warmup_steps = 200,\n",
    "    weight_decay = 0,\n",
    "    # save_strategy = IntervalStrategy.STEPS,\n",
    "    save_steps = 1000,\n",
    "    do_eval = True,\n",
    "    # evaluation_strategy = IntervalStrategy.STEPS,\n",
    "    eval_steps = 109,\n",
    "    include_inputs_for_metrics = True,\n",
    "\n",
    "    # 乱数シード\n",
    "    seed = 2630987289,\n",
    "\n",
    "    # logging_dir = str(output_path / \"logs\"),\n",
    "    logging_steps= 10,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習結果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = {\"score_spanwise_details\": {\"prej\": {\"CORRECT\": 234, \"WRONG_SPAN\": 36, \"MISSING\": 6, \"SPURIOUS\": 32, \"WRONG_LABEL_SPAN\": 3}, \"diff\": {\"CORRECT\": 64, \"MISSING\": 9, \"SPURIOUS\": 19, \"WRONG_SPAN\": 9, \"WRONG_LABEL_SPAN\": 1}, \"deg\": {\"CORRECT\": 222, \"SPURIOUS\": 56, \"MISSING\": 35, \"WRONG_LABEL_SPAN\": 3, \"WRONG_SPAN\": 17, \"WRONG_LABEL\": 4}, \"cont\": {\"CORRECT\": 85, \"SPURIOUS\": 68, \"MISSING\": 28, \"WRONG_SPAN\": 37, \"WRONG_LABEL\": 3, \"WRONG_LABEL_SPAN\": 2}}, \"score_spanwise\": {\"prej\": {\"possible_entries\": 279, \"actual_entries\": 305, \"precision_strict\": 0.7672131147540984, \"recall_strict\": 0.8387096774193549, \"F1_strict\": 0.863013698630137, \"precision_partial\": 0.8262295081967214, \"recall_partial\": 0.9032258064516129}, \"diff\": {\"possible_entries\": 83, \"actual_entries\": 93, \"precision_strict\": 0.6881720430107527, \"recall_strict\": 0.7710843373493976, \"F1_strict\": 0.7784090909090909, \"precision_partial\": 0.7365591397849462, \"recall_partial\": 0.8253012048192772}, \"deg\": {\"possible_entries\": 281, \"actual_entries\": 302, \"precision_strict\": 0.7350993377483444, \"recall_strict\": 0.7900355871886121, \"F1_strict\": 0.7907375643224699, \"precision_partial\": 0.7632450331125827, \"recall_partial\": 0.8202846975088968}, \"cont\": {\"possible_entries\": 155, \"actual_entries\": 195, \"precision_strict\": 0.4358974358974359, \"recall_strict\": 0.5483870967741935, \"F1_strict\": 0.5914285714285714, \"precision_partial\": 0.5307692307692308, \"recall_partial\": 0.667741935483871}}, \"score_spanwise_F1_strict\": 0.7558972313225674, \"score_tokenwise\": {\"IGNORE\": {\"precision\": 0.0, \"recall\": 0.0, \"f1-score\": 0.0, \"support\": 0}, \"O\": {\"precision\": 0.9365750528541226, \"recall\": 0.8965961361545538, \"f1-score\": 0.9161496521902613, \"support\": 5435}, \"B-deg\": {\"precision\": 0.7777777777777778, \"recall\": 0.8321678321678322, \"f1-score\": 0.8040540540540541, \"support\": 286}, \"B-prej\": {\"precision\": 0.8372881355932204, \"recall\": 0.8260869565217391, \"f1-score\": 0.8316498316498316, \"support\": 299}, \"B-cont\": {\"precision\": 0.6368715083798883, \"recall\": 0.6909090909090909, \"f1-score\": 0.6627906976744187, \"support\": 165}, \"B-diff\": {\"precision\": 0.7526881720430108, \"recall\": 0.7865168539325843, \"f1-score\": 0.7692307692307693, \"support\": 89}, \"I-deg\": {\"precision\": 0.6951219512195121, \"recall\": 0.7307692307692307, \"f1-score\": 0.7125, \"support\": 78}, \"I-prej\": {\"precision\": 0.8465732087227414, \"recall\": 0.9394987035436474, \"f1-score\": 0.8906185989348627, \"support\": 1157}, \"I-cont\": {\"precision\": 0.6471518987341772, \"recall\": 0.7226148409893993, \"f1-score\": 0.6828046744574291, \"support\": 566}, \"I-diff\": {\"precision\": 0.7142857142857143, \"recall\": 0.7222222222222222, \"f1-score\": 0.7182320441988951, \"support\": 90}, \"micro avg\": {\"precision\": 0.8769136558481323, \"recall\": 0.8769136558481323, \"f1-score\": 0.8769136558481323, \"support\": 8165}, \"macro avg\": {\"precision\": 0.6844333419610165, \"recall\": 0.7147381867210301, \"f1-score\": 0.6988030322390523, \"support\": 8165}, \"weighted avg\": {\"precision\": 0.881742860881822, \"recall\": 0.8769136558481323, \"f1-score\": 0.8784870999440403, \"support\": 8165}}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORRECT</th>\n",
       "      <th>WRONG_SPAN</th>\n",
       "      <th>MISSING</th>\n",
       "      <th>SPURIOUS</th>\n",
       "      <th>WRONG_LABEL_SPAN</th>\n",
       "      <th>WRONG_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>234</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>32</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>64</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>222</td>\n",
       "      <td>17</td>\n",
       "      <td>35</td>\n",
       "      <td>56</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>85</td>\n",
       "      <td>37</td>\n",
       "      <td>28</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CORRECT  WRONG_SPAN  MISSING  SPURIOUS  WRONG_LABEL_SPAN  WRONG_LABEL\n",
       "prej      234          36        6        32                 3          NaN\n",
       "diff       64           9        9        19                 1          NaN\n",
       "deg       222          17       35        56                 3          4.0\n",
       "cont       85          37       28        68                 2          3.0"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データカウント\n",
    "df_res_count = pd.DataFrame.from_dict(\n",
    "    result[\"score_spanwise_details\"],\n",
    "    orient = \"index\",\n",
    ")\n",
    "\n",
    "df_res_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* CORRECT: ぴったり\n",
    "* WRONG_SPAN: spanにずれがある。\n",
    "* SPURIOUS: 正解データにないspanを予測してしまっている。\n",
    "* MISSING: 正解データにあるspanを予測できていない。\n",
    "* WRONG_LABEL_SPAN: spanにずれがあり，かつ，ラベルも間違っている。\n",
    "* WRONG_LABEL: spanにずれはないが，ラベルが間違っている。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>possible_entries</th>\n",
       "      <th>actual_entries</th>\n",
       "      <th>precision_strict</th>\n",
       "      <th>recall_strict</th>\n",
       "      <th>F1_strict</th>\n",
       "      <th>precision_partial</th>\n",
       "      <th>recall_partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>279</td>\n",
       "      <td>305</td>\n",
       "      <td>0.767213</td>\n",
       "      <td>0.838710</td>\n",
       "      <td>0.863014</td>\n",
       "      <td>0.826230</td>\n",
       "      <td>0.903226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>83</td>\n",
       "      <td>93</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>0.771084</td>\n",
       "      <td>0.778409</td>\n",
       "      <td>0.736559</td>\n",
       "      <td>0.825301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>281</td>\n",
       "      <td>302</td>\n",
       "      <td>0.735099</td>\n",
       "      <td>0.790036</td>\n",
       "      <td>0.790738</td>\n",
       "      <td>0.763245</td>\n",
       "      <td>0.820285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>155</td>\n",
       "      <td>195</td>\n",
       "      <td>0.435897</td>\n",
       "      <td>0.548387</td>\n",
       "      <td>0.591429</td>\n",
       "      <td>0.530769</td>\n",
       "      <td>0.667742</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      possible_entries  actual_entries  precision_strict  recall_strict  \\\n",
       "prej               279             305          0.767213       0.838710   \n",
       "diff                83              93          0.688172       0.771084   \n",
       "deg                281             302          0.735099       0.790036   \n",
       "cont               155             195          0.435897       0.548387   \n",
       "\n",
       "      F1_strict  precision_partial  recall_partial  \n",
       "prej   0.863014           0.826230        0.903226  \n",
       "diff   0.778409           0.736559        0.825301  \n",
       "deg    0.790738           0.763245        0.820285  \n",
       "cont   0.591429           0.530769        0.667742  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 統計\n",
    "df_res_stat = pd.DataFrame.from_dict(\n",
    "    result[\"score_spanwise\"],\n",
    "    orient = \"index\",\n",
    ")\n",
    "\n",
    "df_res_stat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 凡例\n",
    "\n",
    "* `possible_entries`: 予測されたspanの数\n",
    "    ```\n",
    "    ct[\"CORRECT\"] + ct[\"WRONG_SPAN\"] + ct[\"WRONG_LABEL\"] + ct[\"WRONG_LABEL_SPAN\"] + ct[\"MISSING\"]\n",
    "    ```\n",
    "* `actual_entires`: テストデータにあるspanの数\n",
    "    ```\n",
    "    res[\"possible_entries\"] - ct[\"MISSING\"] + ct[\"SPURIOUS\"]\n",
    "    ```\n",
    "* `precision_strict`: 予測のうち，当たっているものの数\n",
    "    ```\n",
    "    ct[\"CORRECT\"] / res[\"actual_entries\"]\n",
    "    ```\n",
    "* `recall_strict`: テストデータにあるもののうち，予測されたspanの数\n",
    "    ```\n",
    "    ct[\"CORRECT\"] / res[\"possible_entries\"]\n",
    "    ```\n",
    "* `precision_partial`：strictよりも緩い。 WRONG_SPANを50%カウントに入れている。\n",
    "    ```\n",
    "    (ct[\"CORRECT\"] + 0.5 * ct[\"WRONG_SPAN\"]) / res[\"actual_entries\"]\n",
    "    ```\n",
    "* `recall_partial`\n",
    "    ```\n",
    "    (ct[\"CORRECT\"] + 0.5 * ct[\"WRONG_SPAN\"]) / res[\"possible_entries\"]\n",
    "    ```\n",
    "* F1はprecisionとrecallの調和平均"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7558972313225674"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1_strictの単純平均。ラベルのカウントで重みづけることはしていない。\n",
    "result[\"score_spanwise_F1_strict\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 学習結果：連体節なしバージョン"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# まず，連体節に該当する文のIDを抜き出す。\n",
    "\n",
    "TREES_YORI_ADNOMINAL =  ! tregex -s -w '/^(VPrel|Srel|N)/ == /root/' /tmp/comp-yori.psd 2> /dev/null | sort | uniq\n",
    "TREES_KURABE_ADNOMINAL =  ! tregex -s -w '/^(VPrel|Srel|N)/ == /root/' /tmp/comp-kurabe.psd 2> /dev/null | sort | uniq\n",
    "\n",
    "TREES_ADNOMINAL = TREES_YORI_ADNOMINAL + TREES_KURABE_ADNOMINAL\n",
    "\n",
    "import re\n",
    "_RE_TREE_ID = re.compile(r\"\\(ID (?P<ID>[^)]+)\\)\")\n",
    "IDs_ADNOMINAL = [\n",
    "    # tree.group(\"ID\")\n",
    "    tree.group(\"ID\")\n",
    "    for tree in \n",
    "    filter(None, map(_RE_TREE_ID.search, TREES_ADNOMINAL))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration abctreebank--comparative-NER-BCCWJ-fe0cb4ac0d530735\n",
      "Reusing dataset parquet (/home/owner/.cache/huggingface/datasets/abctreebank___parquet/abctreebank--comparative-NER-BCCWJ-fe0cb4ac0d530735/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n",
      "Loading cached processed dataset at /home/owner/.cache/huggingface/datasets/abctreebank___parquet/abctreebank--comparative-NER-BCCWJ-fe0cb4ac0d530735/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-52992c08f197a676.arrow\n",
      "Loading cached processed dataset at /home/owner/.cache/huggingface/datasets/abctreebank___parquet/abctreebank--comparative-NER-BCCWJ-fe0cb4ac0d530735/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-c700223d3fe58d43.arrow\n",
      "100%|██████████| 3/3 [00:21<00:00,  7.31s/ba]\n"
     ]
    }
   ],
   "source": [
    "from typing import Sequence\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.utils.data\n",
    "\n",
    "import datasets\n",
    "from transformers import BertForTokenClassification\n",
    "import evaluate\n",
    "\n",
    "from abct_comp_ner_utils.train import convert_records_to_vectors,ID2LABEL_DETAILED, LABEL2ID, _get_tokenizer, _get_evaluator\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\"./../../comparative-NER-result_2022-08\")\n",
    "\n",
    "assert(isinstance(model, BertForTokenClassification))\n",
    "\n",
    "dataset = datasets.load_dataset(\n",
    "    \"abctreebank/comparative-NER-BCCWJ\",\n",
    "    use_auth_token = True,\n",
    "    split = \"test\",\n",
    ")\n",
    "assert(isinstance(dataset, datasets.Dataset))\n",
    "\n",
    "# 連体節を排除\n",
    "dataset = dataset.filter(\n",
    "    lambda x: x[\"ID\"] not in IDs_ADNOMINAL\n",
    ")\n",
    "\n",
    "dataset = dataset.map(convert_records_to_vectors)\n",
    "\n",
    "model.eval()\n",
    "\n",
    "def _make_spans(\n",
    "    input: Sequence | np.ndarray,\n",
    "    pred: Sequence | np.ndarray\n",
    "):\n",
    "    result = {\n",
    "        \"start\": [],\n",
    "        \"end\": [],\n",
    "        \"label\": [],\n",
    "    }\n",
    "\n",
    "    current_label = ID2LABEL_DETAILED[0][0]\n",
    "    current_span_start: int = 0\n",
    "\n",
    "    for loc, (input_id, label_id) in enumerate(zip(input, pred)):\n",
    "        label = ID2LABEL_DETAILED[label_id][0]\n",
    "\n",
    "        if input_id == 0:\n",
    "            # reached padding\n",
    "            break\n",
    "        elif current_label != label:\n",
    "            # label changed\n",
    "            # conclude the old label\n",
    "            if current_label not in (\"IGNORE\", \"O\"):\n",
    "                result[\"start\"].append(current_span_start)\n",
    "                result[\"end\"].append(loc)\n",
    "                result[\"label\"].append(current_label)\n",
    "            else:\n",
    "                pass\n",
    "\n",
    "            # switch to new label\n",
    "            current_label = label\n",
    "            current_span_start = loc\n",
    "\n",
    "    return result\n",
    "\n",
    "def _decode(tokens):\n",
    "    tokens_decoded = _get_tokenizer().batch_decode(\n",
    "        [t for t in tokens if t != 0],\n",
    "        skip_special_tokens = True,\n",
    "    )\n",
    "\n",
    "    return [t.replace(\" \", \"\") for t in tokens_decoded]\n",
    "\n",
    "def _predict(\n",
    "    examples: datasets.arrow_dataset.Example | datasets.arrow_dataset.Batch\n",
    "):\n",
    "    examples[\"tokens_re\"] = [\n",
    "        _decode(entry) for entry in examples[\"input_ids\"]\n",
    "    ]\n",
    "\n",
    "    predictions_raw = model.forward(\n",
    "        input_ids = torch.tensor(examples[\"input_ids\"]),\n",
    "        attention_mask = torch.tensor(examples[\"attention_mask\"]),\n",
    "        token_type_ids = torch.tensor(examples[\"token_type_ids\"]),\n",
    "    ).logits\n",
    "    match predictions_raw:\n",
    "        case torch.Tensor():\n",
    "            predictions: np.ndarray = predictions_raw.argmax(dim = 2).numpy()\n",
    "        case np.ndarray():\n",
    "            predictions: np.ndarray = predictions_raw.argmax(axis = 2)\n",
    "        case _:\n",
    "            raise TypeError\n",
    "    examples[\"prediction\"] = predictions\n",
    "\n",
    "\n",
    "    examples[\"comp_predicted\"] = [\n",
    "        _make_spans(i, p)\n",
    "        for i, p in zip(examples[\"input_ids\"], predictions)\n",
    "    ]\n",
    "    \n",
    "    return examples\n",
    "\n",
    "dataset = dataset.map(\n",
    "    _predict,\n",
    "    batched = True,\n",
    "    batch_size = 128,\n",
    ")\n",
    "\n",
    "_eval: evaluate.Metric = _get_evaluator(\n",
    "    \"../comparative-NER-metrics\"\n",
    ")\n",
    "\n",
    "res_no_adnom = _eval._compute(\n",
    "    predictions = dataset[\"prediction\"],\n",
    "    references = dataset[\"label_ids\"],\n",
    "    input_ids = dataset[\"input_ids\"],\n",
    "    special_ids = _get_tokenizer().all_special_ids,\n",
    "    label2id = LABEL2ID,\n",
    "    id2label_detailed = ID2LABEL_DETAILED,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORRECT</th>\n",
       "      <th>WRONG_SPAN</th>\n",
       "      <th>SPURIOUS</th>\n",
       "      <th>MISSING</th>\n",
       "      <th>WRONG_LABEL_SPAN</th>\n",
       "      <th>WRONG_LABEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>194</td>\n",
       "      <td>31</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>48</td>\n",
       "      <td>7</td>\n",
       "      <td>16</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>185</td>\n",
       "      <td>12</td>\n",
       "      <td>48</td>\n",
       "      <td>29</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>79</td>\n",
       "      <td>39</td>\n",
       "      <td>66</td>\n",
       "      <td>36</td>\n",
       "      <td>3</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CORRECT  WRONG_SPAN  SPURIOUS  MISSING  WRONG_LABEL_SPAN  WRONG_LABEL\n",
       "prej      194          31        33        5                 3          NaN\n",
       "diff       48           7        16       12                 1          NaN\n",
       "deg       185          12        48       29                 3          2.0\n",
       "cont       79          39        66       36                 3          1.0"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# データカウント\n",
    "df_res_count_no_adnom = pd.DataFrame.from_dict(\n",
    "    res_no_adnom[\"score_spanwise_details\"],\n",
    "    orient = \"index\",\n",
    ")\n",
    "\n",
    "df_res_count_no_adnom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>possible_entries</th>\n",
       "      <th>actual_entries</th>\n",
       "      <th>precision_strict</th>\n",
       "      <th>recall_strict</th>\n",
       "      <th>F1_strict</th>\n",
       "      <th>precision_partial</th>\n",
       "      <th>recall_partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>233</td>\n",
       "      <td>261</td>\n",
       "      <td>0.743295</td>\n",
       "      <td>0.832618</td>\n",
       "      <td>0.848178</td>\n",
       "      <td>0.802682</td>\n",
       "      <td>0.899142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>68</td>\n",
       "      <td>72</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.735714</td>\n",
       "      <td>0.715278</td>\n",
       "      <td>0.757353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>231</td>\n",
       "      <td>250</td>\n",
       "      <td>0.740000</td>\n",
       "      <td>0.800866</td>\n",
       "      <td>0.794179</td>\n",
       "      <td>0.764000</td>\n",
       "      <td>0.826840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>158</td>\n",
       "      <td>188</td>\n",
       "      <td>0.420213</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.569364</td>\n",
       "      <td>0.523936</td>\n",
       "      <td>0.623418</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      possible_entries  actual_entries  precision_strict  recall_strict  \\\n",
       "prej               233             261          0.743295       0.832618   \n",
       "diff                68              72          0.666667       0.705882   \n",
       "deg                231             250          0.740000       0.800866   \n",
       "cont               158             188          0.420213       0.500000   \n",
       "\n",
       "      F1_strict  precision_partial  recall_partial  \n",
       "prej   0.848178           0.802682        0.899142  \n",
       "diff   0.735714           0.715278        0.757353  \n",
       "deg    0.794179           0.764000        0.826840  \n",
       "cont   0.569364           0.523936        0.623418  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res_stat_no_adnom = pd.DataFrame.from_dict(\n",
    "    res_no_adnom[\"score_spanwise\"],\n",
    "    orient = \"index\",\n",
    ")\n",
    "\n",
    "df_res_stat_no_adnom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7368588448486533"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# F1_strictの単純平均。ラベルのカウントで重みづけることはしていない。\n",
    "res_no_adnom[\"score_spanwise_F1_strict\"]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('comparative-ner-utils-sv0RmVnD-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98ff88495b25d3c68e7ba2c5383ef33c76229d3a0872ace53e941ddd39c21b36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
