{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{: <10.2%}'.format\n",
    "\n",
    "import torch\n",
    "from transformers import BertForTokenClassification, BertConfig, IntervalStrategy, TrainingArguments, Trainer\n",
    "import datasets\n",
    "from datasets.arrow_dataset import Dataset\n",
    "import ruamel.yaml\n",
    "yaml = ruamel.yaml.YAML()\n",
    "\n",
    "import abctk.obj.comparative as aoc\n",
    "import abct_comp_ner_utils.models.NER_with_root as nwr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ccbc70a477221d0\n",
      "Found cached dataset parquet (/home/twotrees12/.cache/huggingface/datasets/abctreebank___parquet/default-9ccbc70a477221d0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "60f7340f4d8c4f3b8753020bf16683c5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_raw = datasets.load_dataset(\n",
    "    \"abctreebank/comparative-NER-BCCWJ\",\n",
    "    use_auth_token = True,\n",
    "    revision = \"6c51f916ecd23c32e546a3d4f695c69d8c47e21e\",\n",
    ")\n",
    "ds_test = dataset_raw[\"test\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12fa6e457b6a4d639376c38934592ba9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/960 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dbce6be3ad3d45cdbf23070eddbf1f83",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "BATCH_SIZE = 20\n",
    "\n",
    "tokenizer = nwr.get_tokenizer()\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"abctreebank/comparative-NER-with-root\",\n",
    "    revision = \"ed1b1834de445a5fc998839677d6c40872c8ad3c\",\n",
    "    use_auth_token  = True,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c9a4f81f61544f2599b03ede5dfcb073",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_test = dataset_raw[\"test\"].map(\n",
    "    lambda E: nwr.convert_annotation_entries_to_matrices(\n",
    "        E,\n",
    "        return_type = \"pt\",\n",
    "    ),\n",
    "    batched = True,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba2da4db69e243f9a7b028e0ba89b962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/349 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _chomp(\n",
    "    example: datasets.arrow_dataset.Example\n",
    "):\n",
    "    chomped = aoc.chomp_CompRecord(\n",
    "        tokens_subworeded = example[\"token_subwords\"],\n",
    "        comp = example[\"comp\"],\n",
    "    )\n",
    "\n",
    "    example[\"comp_subword_aligned\"] = chomped[\"comp\"]\n",
    "    return example\n",
    "    \n",
    "ds_test = ds_test.map(_chomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1993f4a336bf4eabaec929c4cf3c04d6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _predict(\n",
    "    examples: datasets.arrow_dataset.Batch\n",
    "):\n",
    "    predictions_raw = model.forward(\n",
    "        input_ids = torch.tensor(examples[\"input_ids\"]).cuda(),\n",
    "        attention_mask = torch.tensor(examples[\"attention_mask\"]).cuda(),\n",
    "        token_type_ids  = torch.tensor(examples[\"token_type_ids\"]).cuda(),\n",
    "        return_dict = True,\n",
    "    )\n",
    "\n",
    "    examples[\"label_ids_predicted_NER\"] = (\n",
    "        predictions_raw.logits\n",
    "        .argmax(dim = 2,)\n",
    "        .detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    return examples\n",
    "# === END ===\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    lambda e: (\n",
    "        nwr.convert_predictions_to_annotations(\n",
    "            _predict(e),\n",
    "            label_ids_key = \"label_ids_predicted_NER\",\n",
    "            comp_key = \"comp_predicted_NER\",\n",
    "        )\n",
    "    ),\n",
    "    batched = True,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")\n",
    "\n",
    "metric_NER = aoc.calc_prediction_metrics(\n",
    "    predictions = ds_test[\"comp_predicted_NER\"],\n",
    "    references = ds_test[\"comp_subword_aligned\"],\n",
    ")\n",
    "ds_test = ds_test.add_column(\n",
    "    \"matching_NER\",\n",
    "    [\n",
    "        aoc.print_AlignResult(\n",
    "            prediction = pred,\n",
    "            reference = ref,\n",
    "            alignment = align\n",
    "        )\n",
    "        for pred, ref, align in zip(\n",
    "            ds_test[\"comp_predicted_NER\"],\n",
    "            ds_test[\"comp_subword_aligned\"],\n",
    "            metric_NER[\"alignments\"],\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_NER_wo_align = metric_NER.copy()\n",
    "del metric_NER_wo_align[\"alignments\"]\n",
    "\n",
    "df_NER = pd.DataFrame.from_dict(\n",
    "    metric_NER_wo_align[\"scores_spanwise\"],\n",
    "    orient = \"index\",\n",
    ").fillna(0).astype(\n",
    "    {\n",
    "        \"CORRECT\": \"int32\", \n",
    "        \"SPURIOUS\": \"int32\", \n",
    "        \"MISSING\": \"int32\", \n",
    "        \"WRONG_SPAN\": \"int32\", \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORRECT</th>\n",
       "      <th>SPURIOUS</th>\n",
       "      <th>MISSING</th>\n",
       "      <th>WRONG_SPAN</th>\n",
       "      <th>precision_strict</th>\n",
       "      <th>recall_strict</th>\n",
       "      <th>F1_strict</th>\n",
       "      <th>precision_partial</th>\n",
       "      <th>recall_partial</th>\n",
       "      <th>F1_partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>228</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>83.82%</td>\n",
       "      <td>89.06%</td>\n",
       "      <td>86.36%</td>\n",
       "      <td>87.50%</td>\n",
       "      <td>92.97%</td>\n",
       "      <td>90.15%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>114</td>\n",
       "      <td>51</td>\n",
       "      <td>27</td>\n",
       "      <td>41</td>\n",
       "      <td>55.34%</td>\n",
       "      <td>62.64%</td>\n",
       "      <td>58.76%</td>\n",
       "      <td>65.29%</td>\n",
       "      <td>73.90%</td>\n",
       "      <td>69.33%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>216</td>\n",
       "      <td>43</td>\n",
       "      <td>35</td>\n",
       "      <td>16</td>\n",
       "      <td>78.55%</td>\n",
       "      <td>80.90%</td>\n",
       "      <td>79.70%</td>\n",
       "      <td>81.45%</td>\n",
       "      <td>83.90%</td>\n",
       "      <td>82.66%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>63</td>\n",
       "      <td>14</td>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>70.79%</td>\n",
       "      <td>75.90%</td>\n",
       "      <td>73.26%</td>\n",
       "      <td>77.53%</td>\n",
       "      <td>83.13%</td>\n",
       "      <td>80.23%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root</th>\n",
       "      <td>135</td>\n",
       "      <td>83</td>\n",
       "      <td>3</td>\n",
       "      <td>115</td>\n",
       "      <td>40.54%</td>\n",
       "      <td>53.36%</td>\n",
       "      <td>46.08%</td>\n",
       "      <td>57.81%</td>\n",
       "      <td>76.09%</td>\n",
       "      <td>65.70%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CORRECT  SPURIOUS  MISSING  WRONG_SPAN  precision_strict  recall_strict  \\\n",
       "prej      228        24        8          20        83.82%         89.06%       \n",
       "cont      114        51       27          41        55.34%         62.64%       \n",
       "deg       216        43       35          16        78.55%         80.90%       \n",
       "diff       63        14        8          12        70.79%         75.90%       \n",
       "root      135        83        3         115        40.54%         53.36%       \n",
       "\n",
       "      F1_strict  precision_partial  recall_partial  F1_partial  \n",
       "prej 86.36%             87.50%          92.97%      90.15%      \n",
       "cont 58.76%             65.29%          73.90%      69.33%      \n",
       "deg  79.70%             81.45%          83.90%      82.66%      \n",
       "diff 73.26%             77.53%          83.13%      80.23%      \n",
       "root 46.08%             57.81%          76.09%      65.70%      "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NER.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\", \"root\"], \n",
    "    [\"CORRECT\", \"SPURIOUS\", \"MISSING\", \"WRONG_SPAN\",\n",
    "        \"precision_strict\", \"recall_strict\", \"F1_strict\",\n",
    "        \"precision_partial\", \"recall_partial\", \"F1_partial\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based model based on Ginza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68a1ae60d83c44bb827f7ef61b2a0541",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/349 [00:00<?, ?ex/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with open(\"./predictions_SpaCy_2023-01-07.jsonl\") as f:\n",
    "    ds_rule_predicted= dict(\n",
    "        (record[\"ID\"], record)\n",
    "        for record in map(\n",
    "            lambda c: aoc.dice_CompRecord(**json.loads(c)),\n",
    "            filter(None, map(str.strip, f))\n",
    "        )\n",
    "    )\n",
    "\n",
    "def _add_rulebased_prediction(\n",
    "    entry, \n",
    "    preds: dict[str, aoc.CompRecord] = ds_rule_predicted\n",
    "):\n",
    "    ID = entry[\"ID\"]\n",
    "    diced = aoc.dice_CompRecord(\n",
    "        tokens = entry[\"tokens\"], comp = entry[\"comp\"],\n",
    "        ID = ID, \n",
    "    )\n",
    "    comp_diced = []\n",
    "    for span in diced[\"comp\"]:\n",
    "        label = span[\"label\"]\n",
    "        if (match := nwr._RE_FEAT_ARTIFACTS.match(label) ):\n",
    "            label = match.group(\"name\") or label\n",
    "        \n",
    "        comp_diced.append(\n",
    "            {\n",
    "                \"start\": span[\"start\"],\n",
    "                \"end\": span[\"end\"],\n",
    "                \"label\": label,\n",
    "            }\n",
    "        )\n",
    "    entry[\"tokens_diced\"] = diced[\"tokens\"]\n",
    "    entry[\"comp_diced\"] = comp_diced\n",
    "    \n",
    "    entry[\"comp_predicted_rulebased\"] = preds[ID][\"comp\"] if ID in preds else None\n",
    "\n",
    "    return entry\n",
    "\n",
    "ds_test = ds_test.map(_add_rulebased_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_rulebased = aoc.calc_prediction_metrics(\n",
    "    predictions = (\n",
    "        rec[\"comp_predicted_rulebased\"] for rec in ds_test\n",
    "        if rec[\"comp_predicted_rulebased\"] is not None\n",
    "    ),\n",
    "    references = (\n",
    "        rec[\"comp_diced\"] for rec in ds_test\n",
    "        if rec[\"comp_predicted_rulebased\"] is not None\n",
    "    )\n",
    ")\n",
    "\n",
    "ds_test = ds_test.add_column(\n",
    "    \"matching_rulebased\",\n",
    "    [\n",
    "        aoc.print_AlignResult(\n",
    "            prediction = pred,\n",
    "            reference = ref,\n",
    "            alignment = align\n",
    "        )\n",
    "        for pred, ref, align in zip(\n",
    "            ds_test[\"comp_predicted_rulebased\"],\n",
    "            ds_test[\"comp_diced\"],\n",
    "            metric_rulebased[\"alignments\"],\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rulebased = pd.DataFrame.from_dict(\n",
    "    metric_rulebased[\"scores_spanwise\"],\n",
    "    orient = \"index\",\n",
    ").fillna(0).astype(\n",
    "    {\n",
    "        \"CORRECT\": \"int32\", \n",
    "        \"SPURIOUS\": \"int32\", \n",
    "        \"MISSING\": \"int32\", \n",
    "        \"WRONG_SPAN\": \"int32\", \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORRECT</th>\n",
       "      <th>SPURIOUS</th>\n",
       "      <th>MISSING</th>\n",
       "      <th>WRONG_SPAN</th>\n",
       "      <th>precision_strict</th>\n",
       "      <th>recall_strict</th>\n",
       "      <th>F1_strict</th>\n",
       "      <th>precision_partial</th>\n",
       "      <th>recall_partial</th>\n",
       "      <th>F1_partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>239</td>\n",
       "      <td>89</td>\n",
       "      <td>4</td>\n",
       "      <td>13</td>\n",
       "      <td>70.09%</td>\n",
       "      <td>93.36%</td>\n",
       "      <td>80.07%</td>\n",
       "      <td>71.99%</td>\n",
       "      <td>95.90%</td>\n",
       "      <td>82.24%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>49</td>\n",
       "      <td>244</td>\n",
       "      <td>78</td>\n",
       "      <td>55</td>\n",
       "      <td>14.08%</td>\n",
       "      <td>26.92%</td>\n",
       "      <td>18.49%</td>\n",
       "      <td>21.98%</td>\n",
       "      <td>42.03%</td>\n",
       "      <td>28.87%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>172</td>\n",
       "      <td>150</td>\n",
       "      <td>85</td>\n",
       "      <td>10</td>\n",
       "      <td>51.81%</td>\n",
       "      <td>64.42%</td>\n",
       "      <td>57.43%</td>\n",
       "      <td>53.31%</td>\n",
       "      <td>66.29%</td>\n",
       "      <td>59.10%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>50</td>\n",
       "      <td>96</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>31.65%</td>\n",
       "      <td>60.24%</td>\n",
       "      <td>41.49%</td>\n",
       "      <td>35.44%</td>\n",
       "      <td>67.47%</td>\n",
       "      <td>46.47%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>253</td>\n",
       "      <td>0</td>\n",
       "      <td>inf%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>inf%</td>\n",
       "      <td>0.00%</td>\n",
       "      <td>0.00%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CORRECT  SPURIOUS  MISSING  WRONG_SPAN  precision_strict  recall_strict  \\\n",
       "prej      239        89        4          13        70.09%         93.36%       \n",
       "cont       49       244       78          55        14.08%         26.92%       \n",
       "deg       172       150       85          10        51.81%         64.42%       \n",
       "diff       50        96       21          12        31.65%         60.24%       \n",
       "root        0         0      253           0        inf%           0.00%        \n",
       "\n",
       "      F1_strict  precision_partial  recall_partial  F1_partial  \n",
       "prej 80.07%             71.99%          95.90%      82.24%      \n",
       "cont 18.49%             21.98%          42.03%      28.87%      \n",
       "deg  57.43%             53.31%          66.29%      59.10%      \n",
       "diff 41.49%             35.44%          67.47%      46.47%      \n",
       "root 0.00%              inf%            0.00%       0.00%       "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rulebased.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\", \"root\"], \n",
    "    [\"CORRECT\", \"SPURIOUS\", \"MISSING\", \"WRONG_SPAN\",\n",
    "        \"precision_strict\", \"recall_strict\", \"F1_strict\",\n",
    "        \"precision_partial\", \"recall_partial\", \"F1_partial\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "788"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rulebased.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\"], \n",
    "    [\"CORRECT\", \"MISSING\", \"WRONG_SPAN\"],\n",
    "].sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "788"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NER.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\"], \n",
    "    [\"CORRECT\", \"MISSING\", \"WRONG_SPAN\"],\n",
    "].sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See each prediction in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./details.yaml\", \"w\") as g:\n",
    "    yaml.dump(\n",
    "        list(\n",
    "            {\n",
    "                \"ID\": entry[\"ID\"],\n",
    "                \"reference_linearlized\": aoc.linearize_annotations(\n",
    "                    tokens = entry[\"tokens\"],\n",
    "                    comp = entry[\"comp\"]\n",
    "                ),\n",
    "                \"predicted_NER_linearized\": aoc.linearize_annotations(\n",
    "                    tokens = entry[\"token_subwords\"],\n",
    "                    comp = entry[\"comp_predicted_NER\"],\n",
    "                ),\n",
    "                \"matching_NER\": entry[\"matching_NER\"],\n",
    "                \"predicted_rulebased_linearized\": aoc.linearize_annotations(\n",
    "                    tokens = entry[\"tokens_diced\"],\n",
    "                    comp = entry[\"comp_predicted_rulebased\"],\n",
    "                ),\n",
    "                \"matching_rulebased\": entry[\"matching_rulebased\"],\n",
    "            }\n",
    "            for entry in ds_test\n",
    "        ),\n",
    "        stream = g,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comparative-ner-utils-TwdyRrPe-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1fa0ffdb9e9fd0b877c4ec03dcf1edf281110581bbc6c24c1d31e34cc50dc31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
