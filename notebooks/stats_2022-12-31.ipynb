{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import itertools\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.options.display.float_format = '{: <10.1%}'.format\n",
    "\n",
    "import torch\n",
    "from transformers import BertForTokenClassification, BertConfig, IntervalStrategy, TrainingArguments, Trainer\n",
    "import datasets\n",
    "from datasets.arrow_dataset import Dataset\n",
    "import ruamel.yaml\n",
    "yaml = ruamel.yaml.YAML()\n",
    "\n",
    "import abctk.obj.comparative as aoc\n",
    "import abct_comp_ner_utils.models.NER_with_root as nwr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-935290dee194d9be\n",
      "Found cached dataset parquet (/home/twotrees12/.cache/huggingface/datasets/abctreebank___parquet/default-935290dee194d9be/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5e17df53a3d4beebccb5d2bf8daf8c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_raw = datasets.load_dataset(\n",
    "    \"abctreebank/comparative-NER-BCCWJ\",\n",
    "    use_auth_token = True,\n",
    "    revision = \"e3cdaf016f1fba88d10194500c313f951b0d2df3\",\n",
    ")\n",
    "ds_test = dataset_raw[\"test\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "_RE_kurabe = re.compile(r\"kurabe\")\n",
    "_RE_rentai = re.compile(r\"関係|連体\")\n",
    "_RE_renyoo = re.compile(r\"連用\")\n",
    "_RE_fromtree = re.compile(r\"^FROM TREE:\")\n",
    "_RE_questionable = re.compile(\"？|\\\\?\")\n",
    "\n",
    "df_ds_all_stats = pd.DataFrame(\n",
    "    data = np.zeros((2, 4), dtype = np.int_),\n",
    "    index = [\"より\", \"比べ\"],\n",
    "    columns = [\"連体\", \"連用\", \"その他比較\", \"非比較\"],\n",
    ")\n",
    "\n",
    "for record in datasets.concatenate_datasets(\n",
    "    [dataset_raw[\"train\"], dataset_raw[\"test\"]],\n",
    "):\n",
    "    index = \"比べ\" if _RE_kurabe.search(record[\"ID\"]) else \"より\"\n",
    "    \n",
    "    comments = tuple(\n",
    "        c for c in record[\"comments\"] \n",
    "        if not _RE_fromtree.search(c)\n",
    "    )\n",
    "\n",
    "    if any(_RE_rentai.search(c) for c in comments):\n",
    "        df_ds_all_stats.loc[index, \"連体\"] += 1\n",
    "    elif any(_RE_renyoo.search(c) for c in comments):\n",
    "        df_ds_all_stats.loc[index, \"連用\"] += 1\n",
    "    elif not record[\"comp\"]:\n",
    "        df_ds_all_stats.loc[index, \"非比較\"] += 1\n",
    "    else:\n",
    "        df_ds_all_stats.loc[index, \"その他比較\"] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>連体</th>\n",
       "      <th>連用</th>\n",
       "      <th>その他比較</th>\n",
       "      <th>非比較</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>より</th>\n",
       "      <td>344</td>\n",
       "      <td>289</td>\n",
       "      <td>1111</td>\n",
       "      <td>778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>比べ</th>\n",
       "      <td>55</td>\n",
       "      <td>103</td>\n",
       "      <td>487</td>\n",
       "      <td>293</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     連体   連用  その他比較  非比較\n",
       "より  344  289   1111  778\n",
       "比べ   55  103    487  293"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ds_all_stats"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NER model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 20\n",
    "\n",
    "tokenizer = nwr.get_tokenizer()\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    \"abctreebank/comparative-NER-with-root\",\n",
    "    revision = \"06e75bfe73a0bdf68ec5c57a93c07ebeb4704126\",\n",
    "    use_auth_token  = True,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/twotrees12/.cache/huggingface/datasets/abctreebank___parquet/default-935290dee194d9be/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-b58d2c44a41c8064.arrow\n"
     ]
    }
   ],
   "source": [
    "ds_test = dataset_raw[\"test\"].map(\n",
    "    lambda E: nwr.convert_annotation_entries_to_matrices(\n",
    "        E,\n",
    "        return_type = \"pt\",\n",
    "    ),\n",
    "    batched = True,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/twotrees12/.cache/huggingface/datasets/abctreebank___parquet/default-935290dee194d9be/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-7b28814ef55a1dcf.arrow\n"
     ]
    }
   ],
   "source": [
    "def _chomp(\n",
    "    example: datasets.arrow_dataset.Example\n",
    "):\n",
    "    chomped = aoc.chomp_CompRecord(\n",
    "        tokens_subworeded = example[\"token_subwords\"],\n",
    "        comp = example[\"comp\"],\n",
    "    )\n",
    "\n",
    "    example[\"comp_subword_aligned\"] = chomped[\"comp\"]\n",
    "    return example\n",
    "    \n",
    "ds_test = ds_test.map(_chomp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/twotrees12/.cache/huggingface/datasets/abctreebank___parquet/default-935290dee194d9be/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-2d5b0c69e46f27b1.arrow\n"
     ]
    }
   ],
   "source": [
    "def _predict(\n",
    "    examples: datasets.arrow_dataset.Batch\n",
    "):\n",
    "    predictions_raw = model.forward(\n",
    "        input_ids = torch.tensor(examples[\"input_ids\"]).cuda(),\n",
    "        attention_mask = torch.tensor(examples[\"attention_mask\"]).cuda(),\n",
    "        token_type_ids  = torch.tensor(examples[\"token_type_ids\"]).cuda(),\n",
    "        return_dict = True,\n",
    "    )\n",
    "\n",
    "    examples[\"label_ids_predicted_NER\"] = (\n",
    "        predictions_raw.logits\n",
    "        .argmax(dim = 2,)\n",
    "        .detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    return examples\n",
    "# === END ===\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    lambda e: (\n",
    "        nwr.convert_predictions_to_annotations(\n",
    "            _predict(e),\n",
    "            label_ids_key = \"label_ids_predicted_NER\",\n",
    "            comp_key = \"comp_predicted_NER\",\n",
    "        )\n",
    "    ),\n",
    "    batched = True,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")\n",
    "\n",
    "metric_NER = aoc.calc_prediction_metrics(\n",
    "    predictions = ds_test[\"comp_predicted_NER\"],\n",
    "    references = ds_test[\"comp_subword_aligned\"],\n",
    ")\n",
    "ds_test = ds_test.add_column(\n",
    "    \"matching_NER\",\n",
    "    [\n",
    "        aoc.print_AlignResult(\n",
    "            prediction = pred,\n",
    "            reference = ref,\n",
    "            alignment = align\n",
    "        )\n",
    "        for pred, ref, align in zip(\n",
    "            ds_test[\"comp_predicted_NER\"],\n",
    "            ds_test[\"comp_subword_aligned\"],\n",
    "            metric_NER[\"alignments\"],\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_NER_wo_align = metric_NER.copy()\n",
    "del metric_NER_wo_align[\"alignments\"]\n",
    "\n",
    "df_NER = pd.DataFrame.from_dict(\n",
    "    metric_NER_wo_align[\"scores_spanwise\"],\n",
    "    orient = \"index\",\n",
    ").fillna(0).astype(\n",
    "    {\n",
    "        \"CORRECT\": \"int32\", \n",
    "        \"SPURIOUS\": \"int32\", \n",
    "        \"MISSING\": \"int32\", \n",
    "        \"WRONG_SPAN\": \"int32\", \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORRECT</th>\n",
       "      <th>SPURIOUS</th>\n",
       "      <th>MISSING</th>\n",
       "      <th>WRONG_SPAN</th>\n",
       "      <th>precision_strict</th>\n",
       "      <th>recall_strict</th>\n",
       "      <th>F1_strict</th>\n",
       "      <th>precision_partial</th>\n",
       "      <th>recall_partial</th>\n",
       "      <th>F1_partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>228</td>\n",
       "      <td>29</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>82.0%</td>\n",
       "      <td>88.7%</td>\n",
       "      <td>85.2%</td>\n",
       "      <td>85.8%</td>\n",
       "      <td>92.8%</td>\n",
       "      <td>89.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>119</td>\n",
       "      <td>53</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>57.5%</td>\n",
       "      <td>67.2%</td>\n",
       "      <td>62.0%</td>\n",
       "      <td>65.9%</td>\n",
       "      <td>77.1%</td>\n",
       "      <td>71.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>219</td>\n",
       "      <td>48</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>79.1%</td>\n",
       "      <td>81.1%</td>\n",
       "      <td>80.1%</td>\n",
       "      <td>80.9%</td>\n",
       "      <td>83.0%</td>\n",
       "      <td>81.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>66</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>77.6%</td>\n",
       "      <td>79.5%</td>\n",
       "      <td>78.6%</td>\n",
       "      <td>83.5%</td>\n",
       "      <td>85.5%</td>\n",
       "      <td>84.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root</th>\n",
       "      <td>141</td>\n",
       "      <td>87</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>41.7%</td>\n",
       "      <td>55.3%</td>\n",
       "      <td>47.6%</td>\n",
       "      <td>58.0%</td>\n",
       "      <td>76.9%</td>\n",
       "      <td>66.1%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CORRECT  SPURIOUS  MISSING  WRONG_SPAN  precision_strict  recall_strict  \\\n",
       "prej      228        29        8          21        82.0%          88.7%        \n",
       "cont      119        53       23          35        57.5%          67.2%        \n",
       "deg       219        48       41          10        79.1%          81.1%        \n",
       "diff       66         9        7          10        77.6%          79.5%        \n",
       "root      141        87        4         110        41.7%          55.3%        \n",
       "\n",
       "      F1_strict  precision_partial  recall_partial  F1_partial  \n",
       "prej 85.2%              85.8%           92.8%       89.2%       \n",
       "cont 62.0%              65.9%           77.1%       71.1%       \n",
       "deg  80.1%              80.9%           83.0%       81.9%       \n",
       "diff 78.6%              83.5%           85.5%       84.5%       \n",
       "root 47.6%              58.0%           76.9%       66.1%       "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NER.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\", \"root\"], \n",
    "    [\"CORRECT\", \"SPURIOUS\", \"MISSING\", \"WRONG_SPAN\",\n",
    "        \"precision_strict\", \"recall_strict\", \"F1_strict\",\n",
    "        \"precision_partial\", \"recall_partial\", \"F1_partial\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See scores without spuriousity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_NER_wo_spurious = aoc.calc_prediction_metrics(\n",
    "    predictions = (\n",
    "        rec[\"comp_predicted_NER\"] for rec in ds_test\n",
    "        if rec[\"comp_subword_aligned\"] \n",
    "    ),\n",
    "    references = (\n",
    "        rec[\"comp_subword_aligned\"] for rec in ds_test\n",
    "        if rec[\"comp_subword_aligned\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "df_NER_wo_spurious = pd.DataFrame.from_dict(\n",
    "    metric_NER_wo_spurious[\"scores_spanwise\"],\n",
    "    orient = \"index\",\n",
    ").fillna(0).astype(\n",
    "    {\n",
    "        \"CORRECT\": \"int32\", \n",
    "        \"SPURIOUS\": \"int32\", \n",
    "        \"MISSING\": \"int32\", \n",
    "        \"WRONG_SPAN\": \"int32\", \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORRECT</th>\n",
       "      <th>SPURIOUS</th>\n",
       "      <th>MISSING</th>\n",
       "      <th>WRONG_SPAN</th>\n",
       "      <th>precision_strict</th>\n",
       "      <th>recall_strict</th>\n",
       "      <th>F1_strict</th>\n",
       "      <th>precision_partial</th>\n",
       "      <th>recall_partial</th>\n",
       "      <th>F1_partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>228</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>21</td>\n",
       "      <td>89.1%</td>\n",
       "      <td>88.7%</td>\n",
       "      <td>88.9%</td>\n",
       "      <td>93.2%</td>\n",
       "      <td>92.8%</td>\n",
       "      <td>93.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>119</td>\n",
       "      <td>39</td>\n",
       "      <td>23</td>\n",
       "      <td>35</td>\n",
       "      <td>61.7%</td>\n",
       "      <td>67.2%</td>\n",
       "      <td>64.3%</td>\n",
       "      <td>70.7%</td>\n",
       "      <td>77.1%</td>\n",
       "      <td>73.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>219</td>\n",
       "      <td>31</td>\n",
       "      <td>41</td>\n",
       "      <td>10</td>\n",
       "      <td>84.2%</td>\n",
       "      <td>81.1%</td>\n",
       "      <td>82.6%</td>\n",
       "      <td>86.2%</td>\n",
       "      <td>83.0%</td>\n",
       "      <td>84.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>66</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>79.5%</td>\n",
       "      <td>79.5%</td>\n",
       "      <td>79.5%</td>\n",
       "      <td>85.5%</td>\n",
       "      <td>85.5%</td>\n",
       "      <td>85.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>root</th>\n",
       "      <td>141</td>\n",
       "      <td>57</td>\n",
       "      <td>4</td>\n",
       "      <td>110</td>\n",
       "      <td>45.8%</td>\n",
       "      <td>55.3%</td>\n",
       "      <td>50.1%</td>\n",
       "      <td>63.6%</td>\n",
       "      <td>76.9%</td>\n",
       "      <td>69.6%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CORRECT  SPURIOUS  MISSING  WRONG_SPAN  precision_strict  recall_strict  \\\n",
       "prej      228         7        8          21        89.1%          88.7%        \n",
       "cont      119        39       23          35        61.7%          67.2%        \n",
       "deg       219        31       41          10        84.2%          81.1%        \n",
       "diff       66         7        7          10        79.5%          79.5%        \n",
       "root      141        57        4         110        45.8%          55.3%        \n",
       "\n",
       "      F1_strict  precision_partial  recall_partial  F1_partial  \n",
       "prej 88.9%              93.2%           92.8%       93.0%       \n",
       "cont 64.3%              70.7%           77.1%       73.8%       \n",
       "deg  82.6%              86.2%           83.0%       84.5%       \n",
       "diff 79.5%              85.5%           85.5%       85.5%       \n",
       "root 50.1%              63.6%           76.9%       69.6%       "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NER_wo_spurious.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\", \"root\"], \n",
    "    [\"CORRECT\", \"SPURIOUS\", \"MISSING\", \"WRONG_SPAN\",\n",
    "        \"precision_strict\", \"recall_strict\", \"F1_strict\",\n",
    "        \"precision_partial\", \"recall_partial\", \"F1_partial\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.045646576872003686"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NER_wo_spurious.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\"], \n",
    "    \"precision_strict\"\n",
    "].mean() - df_NER.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\"], \n",
    "    \"precision_strict\"\n",
    "].mean()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule-based model based on Ginza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/twotrees12/.cache/huggingface/datasets/abctreebank___parquet/default-935290dee194d9be/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-6d663900b78060c8.arrow\n"
     ]
    }
   ],
   "source": [
    "with open(\"./predictions_SpaCy_2023-01-13.jsonl\") as f:\n",
    "    ds_rule_predicted= dict(\n",
    "        (record[\"ID\"], record)\n",
    "        for record in map(\n",
    "            lambda c: aoc.dice_CompRecord(**json.loads(c)),\n",
    "            filter(None, map(str.strip, f))\n",
    "        )\n",
    "    )\n",
    "\n",
    "def _add_rulebased_prediction(\n",
    "    entry, \n",
    "    preds: dict[str, aoc.CompRecord] = ds_rule_predicted\n",
    "):\n",
    "    ID = entry[\"ID\"]\n",
    "    diced = aoc.dice_CompRecord(\n",
    "        tokens = entry[\"tokens\"], comp = entry[\"comp\"],\n",
    "        ID = ID, \n",
    "    )\n",
    "    comp_diced = []\n",
    "    for span in diced[\"comp\"]:\n",
    "        label = span[\"label\"]\n",
    "        if (match := nwr._RE_FEAT_ARTIFACTS.match(label) ):\n",
    "            label = match.group(\"name\") or label\n",
    "        \n",
    "        comp_diced.append(\n",
    "            {\n",
    "                \"start\": span[\"start\"],\n",
    "                \"end\": span[\"end\"],\n",
    "                \"label\": label,\n",
    "            }\n",
    "        )\n",
    "    entry[\"tokens_diced\"] = diced[\"tokens\"]\n",
    "    entry[\"comp_diced\"] = comp_diced\n",
    "    \n",
    "    entry[\"comp_predicted_rulebased\"] = preds[ID][\"comp\"] if ID in preds else None\n",
    "\n",
    "    return entry\n",
    "\n",
    "ds_test = ds_test.map(_add_rulebased_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_rulebased = aoc.calc_prediction_metrics(\n",
    "    predictions = (\n",
    "        rec[\"comp_predicted_rulebased\"] for rec in ds_test\n",
    "    ),\n",
    "    references = (\n",
    "        rec[\"comp_diced\"] for rec in ds_test\n",
    "    )\n",
    ")\n",
    "\n",
    "ds_test = ds_test.add_column(\n",
    "    \"matching_rulebased\",\n",
    "    [\n",
    "        aoc.print_AlignResult(\n",
    "            prediction = pred,\n",
    "            reference = ref,\n",
    "            alignment = align\n",
    "        )\n",
    "        for pred, ref, align in zip(\n",
    "            ds_test[\"comp_predicted_rulebased\"],\n",
    "            ds_test[\"comp_diced\"],\n",
    "            metric_rulebased[\"alignments\"],\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rulebased = pd.DataFrame.from_dict(\n",
    "    metric_rulebased[\"scores_spanwise\"],\n",
    "    orient = \"index\",\n",
    ").fillna(0).astype(\n",
    "    {\n",
    "        \"CORRECT\": \"int32\", \n",
    "        \"SPURIOUS\": \"int32\", \n",
    "        \"MISSING\": \"int32\", \n",
    "        \"WRONG_SPAN\": \"int32\", \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORRECT</th>\n",
       "      <th>SPURIOUS</th>\n",
       "      <th>MISSING</th>\n",
       "      <th>WRONG_SPAN</th>\n",
       "      <th>precision_strict</th>\n",
       "      <th>recall_strict</th>\n",
       "      <th>F1_strict</th>\n",
       "      <th>precision_partial</th>\n",
       "      <th>recall_partial</th>\n",
       "      <th>F1_partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>239</td>\n",
       "      <td>86</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>70.5%</td>\n",
       "      <td>93.0%</td>\n",
       "      <td>80.2%</td>\n",
       "      <td>72.6%</td>\n",
       "      <td>95.7%</td>\n",
       "      <td>82.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>50</td>\n",
       "      <td>104</td>\n",
       "      <td>91</td>\n",
       "      <td>36</td>\n",
       "      <td>26.3%</td>\n",
       "      <td>28.2%</td>\n",
       "      <td>27.2%</td>\n",
       "      <td>35.8%</td>\n",
       "      <td>38.4%</td>\n",
       "      <td>37.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>158</td>\n",
       "      <td>159</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>48.0%</td>\n",
       "      <td>58.5%</td>\n",
       "      <td>52.8%</td>\n",
       "      <td>49.8%</td>\n",
       "      <td>60.7%</td>\n",
       "      <td>54.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>52</td>\n",
       "      <td>62</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>43.0%</td>\n",
       "      <td>62.7%</td>\n",
       "      <td>51.0%</td>\n",
       "      <td>45.9%</td>\n",
       "      <td>66.9%</td>\n",
       "      <td>54.4%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CORRECT  SPURIOUS  MISSING  WRONG_SPAN  precision_strict  recall_strict  \\\n",
       "prej      239        86        4          14        70.5%          93.0%        \n",
       "cont       50       104       91          36        26.3%          28.2%        \n",
       "deg       158       159      100          12        48.0%          58.5%        \n",
       "diff       52        62       24           7        43.0%          62.7%        \n",
       "\n",
       "      F1_strict  precision_partial  recall_partial  F1_partial  \n",
       "prej 80.2%              72.6%           95.7%       82.6%       \n",
       "cont 27.2%              35.8%           38.4%       37.1%       \n",
       "deg  52.8%              49.8%           60.7%       54.8%       \n",
       "diff 51.0%              45.9%           66.9%       54.4%       "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rulebased.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\"], \n",
    "    [\"CORRECT\", \"SPURIOUS\", \"MISSING\", \"WRONG_SPAN\",\n",
    "        \"precision_strict\", \"recall_strict\", \"F1_strict\",\n",
    "        \"precision_partial\", \"recall_partial\", \"F1_partial\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See scores without spuriousity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_rulebased_wo_spurious = aoc.calc_prediction_metrics(\n",
    "    predictions = (\n",
    "        rec[\"comp_predicted_rulebased\"] for rec in ds_test\n",
    "        if rec[\"comp_diced\"] \n",
    "    ),\n",
    "    references = (\n",
    "        rec[\"comp_diced\"] for rec in ds_test\n",
    "        if rec[\"comp_diced\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "df_rulebased_wo_spurious = pd.DataFrame.from_dict(\n",
    "    metric_rulebased_wo_spurious[\"scores_spanwise\"],\n",
    "    orient = \"index\",\n",
    ").fillna(0).astype(\n",
    "    {\n",
    "        \"CORRECT\": \"int32\", \n",
    "        \"SPURIOUS\": \"int32\", \n",
    "        \"MISSING\": \"int32\", \n",
    "        \"WRONG_SPAN\": \"int32\", \n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CORRECT</th>\n",
       "      <th>SPURIOUS</th>\n",
       "      <th>MISSING</th>\n",
       "      <th>WRONG_SPAN</th>\n",
       "      <th>precision_strict</th>\n",
       "      <th>recall_strict</th>\n",
       "      <th>F1_strict</th>\n",
       "      <th>precision_partial</th>\n",
       "      <th>recall_partial</th>\n",
       "      <th>F1_partial</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>prej</th>\n",
       "      <td>239</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>14</td>\n",
       "      <td>94.1%</td>\n",
       "      <td>93.0%</td>\n",
       "      <td>93.5%</td>\n",
       "      <td>96.9%</td>\n",
       "      <td>95.7%</td>\n",
       "      <td>96.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cont</th>\n",
       "      <td>50</td>\n",
       "      <td>66</td>\n",
       "      <td>91</td>\n",
       "      <td>36</td>\n",
       "      <td>32.9%</td>\n",
       "      <td>28.2%</td>\n",
       "      <td>30.4%</td>\n",
       "      <td>44.7%</td>\n",
       "      <td>38.4%</td>\n",
       "      <td>41.3%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>deg</th>\n",
       "      <td>158</td>\n",
       "      <td>82</td>\n",
       "      <td>100</td>\n",
       "      <td>12</td>\n",
       "      <td>62.7%</td>\n",
       "      <td>58.5%</td>\n",
       "      <td>60.5%</td>\n",
       "      <td>65.1%</td>\n",
       "      <td>60.7%</td>\n",
       "      <td>62.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>52</td>\n",
       "      <td>44</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>50.5%</td>\n",
       "      <td>62.7%</td>\n",
       "      <td>55.9%</td>\n",
       "      <td>53.9%</td>\n",
       "      <td>66.9%</td>\n",
       "      <td>59.7%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      CORRECT  SPURIOUS  MISSING  WRONG_SPAN  precision_strict  recall_strict  \\\n",
       "prej      239         1        4          14        94.1%          93.0%        \n",
       "cont       50        66       91          36        32.9%          28.2%        \n",
       "deg       158        82      100          12        62.7%          58.5%        \n",
       "diff       52        44       24           7        50.5%          62.7%        \n",
       "\n",
       "      F1_strict  precision_partial  recall_partial  F1_partial  \n",
       "prej 93.5%              96.9%           95.7%       96.3%       \n",
       "cont 30.4%              44.7%           38.4%       41.3%       \n",
       "deg  60.5%              65.1%           60.7%       62.8%       \n",
       "diff 55.9%              53.9%           66.9%       59.7%       "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_rulebased_wo_spurious.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\"], \n",
    "    [\"CORRECT\", \"SPURIOUS\", \"MISSING\", \"WRONG_SPAN\",\n",
    "        \"precision_strict\", \"recall_strict\", \"F1_strict\",\n",
    "        \"precision_partial\", \"recall_partial\", \"F1_partial\",\n",
    "    ]\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.13089071875441893"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rulebased_wo_spurious.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\"], \n",
    "    \"precision_strict\"\n",
    "].mean() - df_rulebased.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\"], \n",
    "    \"precision_strict\"\n",
    "].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Health Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "787"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_rulebased.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\"], \n",
    "    [\"CORRECT\", \"MISSING\", \"WRONG_SPAN\"],\n",
    "].sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "787"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_NER.loc[\n",
    "    [\"prej\", \"cont\", \"deg\", \"diff\"], \n",
    "    [\"CORRECT\", \"MISSING\", \"WRONG_SPAN\"],\n",
    "].sum().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## See each prediction in detail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./details.yaml\", \"w\") as g:\n",
    "    yaml.dump(\n",
    "        list(\n",
    "            {\n",
    "                \"ID\": entry[\"ID\"],\n",
    "                \"reference_linearlized\": aoc.linearize_annotations(\n",
    "                    tokens = entry[\"tokens\"],\n",
    "                    comp = entry[\"comp\"]\n",
    "                ),\n",
    "                \"predicted_NER_linearized\": aoc.linearize_annotations(\n",
    "                    tokens = entry[\"token_subwords\"],\n",
    "                    comp = entry[\"comp_predicted_NER\"],\n",
    "                ),\n",
    "                \"matching_NER\": entry[\"matching_NER\"],\n",
    "                \"predicted_rulebased_linearized\": aoc.linearize_annotations(\n",
    "                    tokens = entry[\"tokens_diced\"],\n",
    "                    comp = entry[\"comp_predicted_rulebased\"],\n",
    "                ),\n",
    "                \"matching_rulebased\": entry[\"matching_rulebased\"],\n",
    "            }\n",
    "            for entry in ds_test\n",
    "        ),\n",
    "        stream = g,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "comparative-ner-utils-TwdyRrPe-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1fa0ffdb9e9fd0b877c4ec03dcf1edf281110581bbc6c24c1d31e34cc50dc31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
