{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertForTokenClassification, BertConfig, IntervalStrategy, TrainingArguments, Trainer\n",
    "import datasets\n",
    "from datasets.arrow_dataset import Dataset\n",
    "\n",
    "import ruamel.yaml\n",
    "\n",
    "import abctk.obj.comparative as aoc\n",
    "\n",
    "import abct_comp_ner_utils.models.NER_with_root as nwr\n",
    "\n",
    "tokenizer = nwr.get_tokenizer()\n",
    "\n",
    "BATCH_SIZE = 20\n",
    "OUTPUT_PATH = \"../../results_2023-01-09\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration default-9ccbc70a477221d0\n",
      "Found cached dataset parquet (/home/twotrees12/.cache/huggingface/datasets/abctreebank___parquet/default-9ccbc70a477221d0/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6d891394b7774a4a87405995781f90ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_raw = datasets.load_dataset(\n",
    "    \"abctreebank/comparative-NER-BCCWJ\",\n",
    "    use_auth_token = True,\n",
    "    revision = \"6c51f916ecd23c32e546a3d4f695c69d8c47e21e\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbd162c273a4ed7bfd23c438dee97a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/156 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_train: Dataset = dataset_raw[\"train\"]\n",
    "ds_train = ds_train.map(\n",
    "    lambda E: nwr.convert_annotation_entries_to_matrices(\n",
    "        E,\n",
    "        return_type = \"pt\",\n",
    "    ),\n",
    "    batched = True,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    remove_columns = ds_train.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/eval split\n",
    "ds_train_split = ds_train.train_test_split(test_size = 0.1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForTokenClassification: ['cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained(\n",
    "    nwr.BERT_MODEL,\n",
    "    id2label = nwr.ID2LABEL,\n",
    "    label2id = nwr.LABEL2ID,\n",
    ")\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    nwr.BERT_MODEL,\n",
    "    config = config,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir = OUTPUT_PATH,\n",
    "        num_train_epochs = 27,\n",
    "        per_device_train_batch_size = 16,\n",
    "        per_device_eval_batch_size = 16,\n",
    "        learning_rate = 5e-5,\n",
    "        warmup_steps = 200,\n",
    "        weight_decay = 0,\n",
    "        save_strategy = IntervalStrategy.STEPS,\n",
    "        save_steps = 1000,\n",
    "        seed = 2630987289,\n",
    "        logging_dir = f\"{OUTPUT_PATH}/logs\",\n",
    "        logging_steps= 10,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init = lambda: model,\n",
    "    args = training_args,\n",
    "    train_dataset = ds_train_split[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()\n",
    "trainer.save_state()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Configuration saved in /tmp/tmpiq57h0w9/config.json\n",
      "Model weights saved in /tmp/tmpiq57h0w9/pytorch_model.bin\n",
      "Uploading the following files to abctreebank/comparative-NER-with-root: config.json,pytorch_model.bin\n",
      "tokenizer config file saved in /tmp/tmpypgve4j1/tokenizer_config.json\n",
      "Special tokens file saved in /tmp/tmpypgve4j1/special_tokens_map.json\n",
      "Uploading the following files to abctreebank/comparative-NER-with-root: tokenizer_config.json,vocab.txt,special_tokens_map.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/abctreebank/comparative-NER-with-root/commit/ed1b1834de445a5fc998839677d6c40872c8ad3c', commit_message='Upload tokenizer', commit_description='', oid='ed1b1834de445a5fc998839677d6c40872c8ad3c', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.name_or_path = \"cl-tohoku/bert-base-japanese-whole-word-masking\"\n",
    "\n",
    "# To push:\n",
    "# model.push_to_hub(\n",
    "#     \"abctreebank/comparative-NER-with-root\",\n",
    "#     private = True,\n",
    "#     use_auth_token = True,\n",
    "# )\n",
    "# tokenizer.push_to_hub(\n",
    "#     \"abctreebank/comparative-NER-with-root\",\n",
    "#     private = True,\n",
    "#     use_auth_token = True,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../../results_2023-01-09/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"cl-tohoku/bert-base-japanese-whole-word-masking\",\n",
      "  \"architectures\": [\n",
      "    \"BertForTokenClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"deg\",\n",
      "    \"2\": \"prej\",\n",
      "    \"3\": \"cont\",\n",
      "    \"4\": \"diff\",\n",
      "    \"5\": \"root\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"IGNORE\": -100,\n",
      "    \"O\": 0,\n",
      "    \"cont\": 3,\n",
      "    \"deg\": 1,\n",
      "    \"diff\": 4,\n",
      "    \"prej\": 2,\n",
      "    \"root\": 5\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"tokenizer_class\": \"BertJapaneseTokenizer\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.25.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 32000\n",
      "}\n",
      "\n",
      "loading weights file ../../results_2023-01-09/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForTokenClassification.\n",
      "\n",
      "All the weights of BertForTokenClassification were initialized from the model checkpoint at ../../results_2023-01-09.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForTokenClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "SAVED_PATH = OUTPUT_PATH\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    SAVED_PATH,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3cac38532750429a968acd759795bbf7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_test = dataset_raw[\"test\"].map(\n",
    "    lambda E: nwr.convert_annotation_entries_to_matrices(\n",
    "        E,\n",
    "        return_type = \"pt\",\n",
    "    ),\n",
    "    batched = True,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f20546bc06c243379dd95cfb5fb987d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _predict(\n",
    "    examples: datasets.arrow_dataset.Batch\n",
    "):\n",
    "    predictions_raw = model.forward(\n",
    "        input_ids = torch.tensor(examples[\"input_ids\"]).cuda(),\n",
    "        attention_mask = torch.tensor(examples[\"attention_mask\"]).cuda(),\n",
    "        token_type_ids  = torch.tensor(examples[\"token_type_ids\"]).cuda(),\n",
    "        return_dict = True,\n",
    "    )\n",
    "\n",
    "    examples[\"label_ids_predicted\"] = (\n",
    "        predictions_raw.logits\n",
    "        .argmax(dim = 2,)\n",
    "        .detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    return examples\n",
    "# === END ===\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    lambda e: (\n",
    "        nwr.convert_predictions_to_annotations(\n",
    "            nwr.convert_predictions_to_annotations(\n",
    "                _predict(e),\n",
    "                label_ids_key = \"label_ids_predicted\",\n",
    "                comp_key = \"comp_predicted\",\n",
    "            ),\n",
    "            label_ids_key = \"label_ids\",\n",
    "            comp_key = \"comp_subword_aligned\",\n",
    "        )\n",
    "    ),\n",
    "    batched = True,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = nwr.NERWithRootMetrics()\n",
    "metric.add_batch(\n",
    "    predictions = ds_test[\"label_ids_predicted\"],\n",
    "    references = ds_test[\"label_ids\"],\n",
    ")\n",
    "metric_result = metric.compute()\n",
    "ds_test_with_alignments = ds_test.add_column(\n",
    "    \"errors\",\n",
    "    [\n",
    "        [\n",
    "            aoc.MatchSpanResult(jdg).name for _, jdg in itertools.chain(\n",
    "                res.map_pred_to_ref,\n",
    "                res.map_ref_to_pred\n",
    "            )\n",
    "            if jdg != aoc.MatchSpanResult.CORRECT\n",
    "        ]\n",
    "        for res in metric_result[\"alignments\"]\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3f1553a335f04fedb008847139ccd106",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/18 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def _linearize_comp(\n",
    "    batch: datasets.arrow_dataset.Batch\n",
    ") -> datasets.arrow_dataset.Batch:\n",
    "    ls_reference_linear = []\n",
    "    ls_prediction_linear = []\n",
    "    batch_size = len(batch[\"ID\"])\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        ID = batch[\"ID\"][i]\n",
    "        tokens = tuple(\n",
    "                    itertools.takewhile(\n",
    "                lambda t: t not in (\"[SEP]\", \"[PAD]\"),\n",
    "                batch[\"token_subwords\"][i]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ls_reference_linear.append(\n",
    "            aoc.linearize_annotations(\n",
    "                tokens,\n",
    "                batch[\"comp_subword_aligned\"][i],\n",
    "            )\n",
    "        )\n",
    "        ls_prediction_linear.append(\n",
    "            aoc.linearize_annotations(\n",
    "                tokens,\n",
    "                batch[\"comp_predicted\"][i],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    batch[\"reference_linear\"] = ls_reference_linear\n",
    "    batch[\"prediction_linear\"] = ls_prediction_linear\n",
    "\n",
    "    return batch\n",
    "\n",
    "ds_test_with_alignments = ds_test_with_alignments.map(\n",
    "    _linearize_comp,\n",
    "    batched = True,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")\n",
    "\n",
    "ds_test_dump = ds_test_with_alignments.remove_columns(\n",
    "    [\n",
    "        col for col in ds_test_with_alignments.column_names\n",
    "        if col not in (\n",
    "            \"ID\",\n",
    "            \"prediction_linear\",\n",
    "            \"reference_linear\",\n",
    "            \"alignments\",\n",
    "            \"errors\",\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = ruamel.yaml.YAML()\n",
    "with open(\"./result.yaml\", \"w\") as f:\n",
    "    yaml.dump(list(ds_test_dump), f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_result[\"scores_spanwise\"] = { \n",
    "    str(k) : v\n",
    "    for k, v in metric_result[\"scores_spanwise\"].items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8025059415015681"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result[\"F1_partial_average\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.702534994867713"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result[\"F1_strict_average\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      "0.7051070840197694\n",
      "0.5205930807248764\n",
      "\n",
      "cont\n",
      "0.7308707124010554\n",
      "0.6015831134564643\n",
      "\n",
      "prej\n",
      "0.905123339658444\n",
      "0.8690702087286528\n",
      "\n",
      "diff\n",
      "0.8392857142857143\n",
      "0.7499999999999999\n",
      "\n",
      "deg\n",
      "0.8321428571428571\n",
      "0.7714285714285715\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label, res in metric_result[\"scores_spanwise\"].items():\n",
    "    print(label)\n",
    "    print(res[\"F1_partial\"])\n",
    "    print(res[\"F1_strict\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = ruamel.yaml.YAML()\n",
    "with open(\"scores.yaml\", \"w\") as g:\n",
    "    yaml.dump(\n",
    "        {\n",
    "            k : v for k, v in metric_result.items()\n",
    "            if k != \"alignments\"\n",
    "        },\n",
    "        stream = g,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.6 ('comparative-ner-utils-TwdyRrPe-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a1fa0ffdb9e9fd0b877c4ec03dcf1edf281110581bbc6c24c1d31e34cc50dc31"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
