{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertForTokenClassification, BertConfig, IntervalStrategy, TrainingArguments, Trainer\n",
    "import datasets\n",
    "from datasets.arrow_dataset import Dataset\n",
    "\n",
    "import ruamel.yaml\n",
    "\n",
    "import abctk.obj.comparative as aoc\n",
    "\n",
    "import abct_comp_ner_utils.models.NER_with_root as nwr\n",
    "\n",
    "tokenizer = nwr.get_tokenizer()\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "OUTPUT_PATH = \"../../results_2022-12-24\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using custom data configuration abctreebank--comparative-NER-BCCWJ-c32c3cdce4ba824a\n",
      "Found cached dataset parquet (/home/owner/.cache/huggingface/datasets/abctreebank___parquet/abctreebank--comparative-NER-BCCWJ-c32c3cdce4ba824a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c41b97e06b4eda8b082958cc68f4ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataset_raw = datasets.load_dataset(\n",
    "    \"abctreebank/comparative-NER-BCCWJ\",\n",
    "    use_auth_token = True,\n",
    "    revision = \"de8fe2785391897efc898be36d695d8164863045\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adf49211bd3340e5bf4a2fb79975841e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/98 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds_train: Dataset = dataset_raw[\"train\"]\n",
    "ds_train = ds_train.map(\n",
    "    lambda E: nwr.convert_annotation_entries_to_matrices(\n",
    "        E,\n",
    "        return_type = \"pt\",\n",
    "    ),\n",
    "    batched = True,\n",
    "    batch_size = BATCH_SIZE,\n",
    "    remove_columns = ds_train.column_names,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/eval split\n",
    "ds_train_split = ds_train.train_test_split(test_size = 0.1, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking were not used when initializing BertForTokenClassification: ['cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at cl-tohoku/bert-base-japanese-whole-word-masking and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "config = BertConfig.from_pretrained(\n",
    "    nwr.BERT_MODEL,\n",
    "    id2label = nwr.ID2LABEL,\n",
    "    label2id = nwr.LABEL2ID,\n",
    ")\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    nwr.BERT_MODEL,\n",
    "    config = config,\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "        output_dir = OUTPUT_PATH,\n",
    "        num_train_epochs = 27,\n",
    "        per_device_train_batch_size = 64,\n",
    "        per_device_eval_batch_size = 128,\n",
    "        learning_rate = 5e-5,\n",
    "        warmup_steps = 200,\n",
    "        weight_decay = 0,\n",
    "        save_strategy = IntervalStrategy.STEPS,\n",
    "        save_steps = 1000,\n",
    "        seed = 2630987289,\n",
    "        logging_dir = f\"{OUTPUT_PATH}/logs\",\n",
    "        logging_steps= 10,\n",
    "    )\n",
    "\n",
    "trainer = Trainer(\n",
    "    model_init = lambda: model,\n",
    "    args = training_args,\n",
    "    train_dataset = ds_train_split[\"train\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The following columns in the training set don't have a corresponding argument in `BertForTokenClassification.forward` and have been ignored: token_subwords. If token_subwords are not expected by `BertForTokenClassification.forward`,  you can safely ignore this message.\n",
      "/home/owner/.cache/pypoetry/virtualenvs/comparative-ner-utils-sv0RmVnD-py3.10/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 2808\n",
      "  Num Epochs = 27\n",
      "  Instantaneous batch size per device = 64\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1188\n",
      "  Number of trainable parameters = 110031366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "718be00e1a3b4f098faa5700056e5405",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1188 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6427, 'learning_rate': 2.5e-06, 'epoch': 0.23}\n",
      "{'loss': 1.3992, 'learning_rate': 5e-06, 'epoch': 0.45}\n",
      "{'loss': 0.9007, 'learning_rate': 7.5e-06, 'epoch': 0.68}\n",
      "{'loss': 0.3189, 'learning_rate': 1e-05, 'epoch': 0.91}\n",
      "{'loss': 0.2063, 'learning_rate': 1.25e-05, 'epoch': 1.14}\n",
      "{'loss': 0.1396, 'learning_rate': 1.5e-05, 'epoch': 1.36}\n",
      "{'loss': 0.109, 'learning_rate': 1.75e-05, 'epoch': 1.59}\n",
      "{'loss': 0.0936, 'learning_rate': 2e-05, 'epoch': 1.82}\n",
      "{'loss': 0.078, 'learning_rate': 2.25e-05, 'epoch': 2.05}\n",
      "{'loss': 0.0599, 'learning_rate': 2.5e-05, 'epoch': 2.27}\n",
      "{'loss': 0.0563, 'learning_rate': 2.7500000000000004e-05, 'epoch': 2.5}\n",
      "{'loss': 0.0487, 'learning_rate': 3e-05, 'epoch': 2.73}\n",
      "{'loss': 0.0484, 'learning_rate': 3.2500000000000004e-05, 'epoch': 2.95}\n",
      "{'loss': 0.0444, 'learning_rate': 3.5e-05, 'epoch': 3.18}\n",
      "{'loss': 0.0389, 'learning_rate': 3.7500000000000003e-05, 'epoch': 3.41}\n",
      "{'loss': 0.0379, 'learning_rate': 4e-05, 'epoch': 3.64}\n",
      "{'loss': 0.0384, 'learning_rate': 4.25e-05, 'epoch': 3.86}\n",
      "{'loss': 0.0316, 'learning_rate': 4.5e-05, 'epoch': 4.09}\n",
      "{'loss': 0.0281, 'learning_rate': 4.75e-05, 'epoch': 4.32}\n",
      "{'loss': 0.029, 'learning_rate': 5e-05, 'epoch': 4.55}\n",
      "{'loss': 0.0281, 'learning_rate': 4.9493927125506076e-05, 'epoch': 4.77}\n",
      "{'loss': 0.0285, 'learning_rate': 4.898785425101215e-05, 'epoch': 5.0}\n",
      "{'loss': 0.0204, 'learning_rate': 4.848178137651822e-05, 'epoch': 5.23}\n",
      "{'loss': 0.0208, 'learning_rate': 4.797570850202429e-05, 'epoch': 5.45}\n",
      "{'loss': 0.019, 'learning_rate': 4.746963562753037e-05, 'epoch': 5.68}\n",
      "{'loss': 0.0204, 'learning_rate': 4.6963562753036435e-05, 'epoch': 5.91}\n",
      "{'loss': 0.0176, 'learning_rate': 4.6457489878542516e-05, 'epoch': 6.14}\n",
      "{'loss': 0.0162, 'learning_rate': 4.595141700404859e-05, 'epoch': 6.36}\n",
      "{'loss': 0.0156, 'learning_rate': 4.5445344129554655e-05, 'epoch': 6.59}\n",
      "{'loss': 0.0143, 'learning_rate': 4.4939271255060735e-05, 'epoch': 6.82}\n",
      "{'loss': 0.0148, 'learning_rate': 4.44331983805668e-05, 'epoch': 7.05}\n",
      "{'loss': 0.0121, 'learning_rate': 4.3927125506072875e-05, 'epoch': 7.27}\n",
      "{'loss': 0.012, 'learning_rate': 4.342105263157895e-05, 'epoch': 7.5}\n",
      "{'loss': 0.0135, 'learning_rate': 4.291497975708502e-05, 'epoch': 7.73}\n",
      "{'loss': 0.0156, 'learning_rate': 4.2408906882591095e-05, 'epoch': 7.95}\n",
      "{'loss': 0.0116, 'learning_rate': 4.190283400809717e-05, 'epoch': 8.18}\n",
      "{'loss': 0.0107, 'learning_rate': 4.139676113360324e-05, 'epoch': 8.41}\n",
      "{'loss': 0.0106, 'learning_rate': 4.089068825910931e-05, 'epoch': 8.64}\n",
      "{'loss': 0.0107, 'learning_rate': 4.038461538461539e-05, 'epoch': 8.86}\n",
      "{'loss': 0.0108, 'learning_rate': 3.9878542510121455e-05, 'epoch': 9.09}\n",
      "{'loss': 0.0081, 'learning_rate': 3.9372469635627535e-05, 'epoch': 9.32}\n",
      "{'loss': 0.0085, 'learning_rate': 3.886639676113361e-05, 'epoch': 9.55}\n",
      "{'loss': 0.0099, 'learning_rate': 3.8360323886639675e-05, 'epoch': 9.77}\n",
      "{'loss': 0.0086, 'learning_rate': 3.7854251012145755e-05, 'epoch': 10.0}\n",
      "{'loss': 0.0076, 'learning_rate': 3.734817813765182e-05, 'epoch': 10.23}\n",
      "{'loss': 0.0063, 'learning_rate': 3.6842105263157895e-05, 'epoch': 10.45}\n",
      "{'loss': 0.008, 'learning_rate': 3.633603238866397e-05, 'epoch': 10.68}\n",
      "{'loss': 0.007, 'learning_rate': 3.582995951417004e-05, 'epoch': 10.91}\n",
      "{'loss': 0.0069, 'learning_rate': 3.5323886639676115e-05, 'epoch': 11.14}\n",
      "{'loss': 0.0059, 'learning_rate': 3.481781376518219e-05, 'epoch': 11.36}\n",
      "{'loss': 0.0063, 'learning_rate': 3.431174089068826e-05, 'epoch': 11.59}\n",
      "{'loss': 0.0071, 'learning_rate': 3.3805668016194335e-05, 'epoch': 11.82}\n",
      "{'loss': 0.006, 'learning_rate': 3.329959514170041e-05, 'epoch': 12.05}\n",
      "{'loss': 0.006, 'learning_rate': 3.279352226720648e-05, 'epoch': 12.27}\n",
      "{'loss': 0.0055, 'learning_rate': 3.2287449392712554e-05, 'epoch': 12.5}\n",
      "{'loss': 0.0062, 'learning_rate': 3.178137651821863e-05, 'epoch': 12.73}\n",
      "{'loss': 0.0055, 'learning_rate': 3.1275303643724694e-05, 'epoch': 12.95}\n",
      "{'loss': 0.0047, 'learning_rate': 3.0769230769230774e-05, 'epoch': 13.18}\n",
      "{'loss': 0.0048, 'learning_rate': 3.0263157894736844e-05, 'epoch': 13.41}\n",
      "{'loss': 0.0046, 'learning_rate': 2.9757085020242914e-05, 'epoch': 13.64}\n",
      "{'loss': 0.0048, 'learning_rate': 2.925101214574899e-05, 'epoch': 13.86}\n",
      "{'loss': 0.0048, 'learning_rate': 2.874493927125506e-05, 'epoch': 14.09}\n",
      "{'loss': 0.0036, 'learning_rate': 2.823886639676113e-05, 'epoch': 14.32}\n",
      "{'loss': 0.0043, 'learning_rate': 2.7732793522267207e-05, 'epoch': 14.55}\n",
      "{'loss': 0.0046, 'learning_rate': 2.722672064777328e-05, 'epoch': 14.77}\n",
      "{'loss': 0.0043, 'learning_rate': 2.6720647773279357e-05, 'epoch': 15.0}\n",
      "{'loss': 0.0033, 'learning_rate': 2.6214574898785427e-05, 'epoch': 15.23}\n",
      "{'loss': 0.0049, 'learning_rate': 2.5708502024291497e-05, 'epoch': 15.45}\n",
      "{'loss': 0.0043, 'learning_rate': 2.5202429149797574e-05, 'epoch': 15.68}\n",
      "{'loss': 0.004, 'learning_rate': 2.4696356275303644e-05, 'epoch': 15.91}\n",
      "{'loss': 0.0035, 'learning_rate': 2.4190283400809717e-05, 'epoch': 16.14}\n",
      "{'loss': 0.0035, 'learning_rate': 2.368421052631579e-05, 'epoch': 16.36}\n",
      "{'loss': 0.0035, 'learning_rate': 2.3178137651821864e-05, 'epoch': 16.59}\n",
      "{'loss': 0.0038, 'learning_rate': 2.2672064777327937e-05, 'epoch': 16.82}\n",
      "{'loss': 0.0031, 'learning_rate': 2.216599190283401e-05, 'epoch': 17.05}\n",
      "{'loss': 0.0029, 'learning_rate': 2.165991902834008e-05, 'epoch': 17.27}\n",
      "{'loss': 0.0031, 'learning_rate': 2.1153846153846154e-05, 'epoch': 17.5}\n",
      "{'loss': 0.0032, 'learning_rate': 2.0647773279352227e-05, 'epoch': 17.73}\n",
      "{'loss': 0.0031, 'learning_rate': 2.0141700404858304e-05, 'epoch': 17.95}\n",
      "{'loss': 0.0029, 'learning_rate': 1.9635627530364373e-05, 'epoch': 18.18}\n",
      "{'loss': 0.0034, 'learning_rate': 1.9129554655870447e-05, 'epoch': 18.41}\n",
      "{'loss': 0.0028, 'learning_rate': 1.862348178137652e-05, 'epoch': 18.64}\n",
      "{'loss': 0.0026, 'learning_rate': 1.811740890688259e-05, 'epoch': 18.86}\n",
      "{'loss': 0.0028, 'learning_rate': 1.7611336032388663e-05, 'epoch': 19.09}\n",
      "{'loss': 0.0028, 'learning_rate': 1.7105263157894737e-05, 'epoch': 19.32}\n",
      "{'loss': 0.0028, 'learning_rate': 1.6599190283400813e-05, 'epoch': 19.55}\n",
      "{'loss': 0.0025, 'learning_rate': 1.6093117408906883e-05, 'epoch': 19.77}\n",
      "{'loss': 0.002, 'learning_rate': 1.5587044534412957e-05, 'epoch': 20.0}\n",
      "{'loss': 0.003, 'learning_rate': 1.508097165991903e-05, 'epoch': 20.23}\n",
      "{'loss': 0.002, 'learning_rate': 1.4574898785425101e-05, 'epoch': 20.45}\n",
      "{'loss': 0.0024, 'learning_rate': 1.4068825910931175e-05, 'epoch': 20.68}\n",
      "{'loss': 0.0023, 'learning_rate': 1.3562753036437248e-05, 'epoch': 20.91}\n",
      "{'loss': 0.002, 'learning_rate': 1.3056680161943321e-05, 'epoch': 21.14}\n",
      "{'loss': 0.0021, 'learning_rate': 1.2550607287449393e-05, 'epoch': 21.36}\n",
      "{'loss': 0.0028, 'learning_rate': 1.2044534412955466e-05, 'epoch': 21.59}\n",
      "{'loss': 0.0022, 'learning_rate': 1.153846153846154e-05, 'epoch': 21.82}\n",
      "{'loss': 0.0024, 'learning_rate': 1.1032388663967611e-05, 'epoch': 22.05}\n",
      "{'loss': 0.002, 'learning_rate': 1.0526315789473684e-05, 'epoch': 22.27}\n",
      "{'loss': 0.0026, 'learning_rate': 1.0020242914979758e-05, 'epoch': 22.5}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ../../results_2022-12-24/checkpoint-1000\n",
      "Configuration saved in ../../results_2022-12-24/checkpoint-1000/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.002, 'learning_rate': 9.51417004048583e-06, 'epoch': 22.73}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../../results_2022-12-24/checkpoint-1000/pytorch_model.bin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.002, 'learning_rate': 9.008097165991904e-06, 'epoch': 22.95}\n",
      "{'loss': 0.0022, 'learning_rate': 8.502024291497976e-06, 'epoch': 23.18}\n",
      "{'loss': 0.0017, 'learning_rate': 7.99595141700405e-06, 'epoch': 23.41}\n",
      "{'loss': 0.0024, 'learning_rate': 7.489878542510122e-06, 'epoch': 23.64}\n",
      "{'loss': 0.0016, 'learning_rate': 6.983805668016195e-06, 'epoch': 23.86}\n",
      "{'loss': 0.0021, 'learning_rate': 6.4777327935222675e-06, 'epoch': 24.09}\n",
      "{'loss': 0.0015, 'learning_rate': 5.971659919028341e-06, 'epoch': 24.32}\n",
      "{'loss': 0.002, 'learning_rate': 5.465587044534413e-06, 'epoch': 24.55}\n",
      "{'loss': 0.002, 'learning_rate': 4.9595141700404865e-06, 'epoch': 24.77}\n",
      "{'loss': 0.002, 'learning_rate': 4.453441295546559e-06, 'epoch': 25.0}\n",
      "{'loss': 0.0017, 'learning_rate': 3.9473684210526315e-06, 'epoch': 25.23}\n",
      "{'loss': 0.0018, 'learning_rate': 3.4412955465587043e-06, 'epoch': 25.45}\n",
      "{'loss': 0.002, 'learning_rate': 2.9352226720647772e-06, 'epoch': 25.68}\n",
      "{'loss': 0.0018, 'learning_rate': 2.4291497975708505e-06, 'epoch': 25.91}\n",
      "{'loss': 0.0017, 'learning_rate': 1.9230769230769234e-06, 'epoch': 26.14}\n",
      "{'loss': 0.0018, 'learning_rate': 1.417004048582996e-06, 'epoch': 26.36}\n",
      "{'loss': 0.0019, 'learning_rate': 9.109311740890688e-07, 'epoch': 26.59}\n",
      "{'loss': 0.0015, 'learning_rate': 4.048582995951417e-07, 'epoch': 26.82}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to ../../results_2022-12-24\n",
      "Configuration saved in ../../results_2022-12-24/config.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 646.3331, 'train_samples_per_second': 117.302, 'train_steps_per_second': 1.838, 'train_loss': 0.050229049744774344, 'epoch': 27.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Model weights saved in ../../results_2022-12-24/pytorch_model.bin\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.save_state()\n",
    "trainer.save_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAVED_PATH = OUTPUT_PATH\n",
    "\n",
    "model = BertForTokenClassification.from_pretrained(\n",
    "    SAVED_PATH,\n",
    ").cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/owner/.cache/huggingface/datasets/abctreebank___parquet/abctreebank--comparative-NER-BCCWJ-c32c3cdce4ba824a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-767a4322f191f28d.arrow\n"
     ]
    }
   ],
   "source": [
    "ds_test = dataset_raw[\"test\"].map(\n",
    "    lambda E: nwr.convert_annotation_entries_to_matrices(\n",
    "        E,\n",
    "        return_type = \"pt\",\n",
    "    ),\n",
    "    batched = True,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at /home/owner/.cache/huggingface/datasets/abctreebank___parquet/abctreebank--comparative-NER-BCCWJ-c32c3cdce4ba824a/0.0.0/2a3b91fbd88a2c90d1dbbb32b460cf621d31bd5b05b934492fdef7d8d6f236ec/cache-b55722157743c6c5.arrow\n"
     ]
    }
   ],
   "source": [
    "def _predict(\n",
    "    examples: datasets.arrow_dataset.Batch\n",
    "):\n",
    "    predictions_raw = model.forward(\n",
    "        input_ids = torch.tensor(examples[\"input_ids\"]).cuda(),\n",
    "        attention_mask = torch.tensor(examples[\"attention_mask\"]).cuda(),\n",
    "        token_type_ids  = torch.tensor(examples[\"token_type_ids\"]).cuda(),\n",
    "        return_dict = True,\n",
    "    )\n",
    "\n",
    "    examples[\"label_ids_predicted\"] = (\n",
    "        predictions_raw.logits\n",
    "        .argmax(dim = 2,)\n",
    "        .detach()\n",
    "        .cpu()\n",
    "        .numpy()\n",
    "    )\n",
    "\n",
    "    return examples\n",
    "# === END ===\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    lambda e: (\n",
    "        nwr.convert_predictions_to_annotations(\n",
    "            nwr.convert_predictions_to_annotations(\n",
    "                _predict(e),\n",
    "                label_ids_key = \"label_ids_predicted\",\n",
    "                comp_key = \"comp_predicted\",\n",
    "            ),\n",
    "            label_ids_key = \"label_ids\",\n",
    "            comp_key = \"comp_subword_aligned\",\n",
    "        )\n",
    "    ),\n",
    "    batched = True,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = nwr.NERWithRootMetrics()\n",
    "metric.add_batch(\n",
    "    predictions = ds_test[\"label_ids_predicted\"],\n",
    "    references = ds_test[\"label_ids\"],\n",
    ")\n",
    "metric_result = metric.compute()\n",
    "ds_test_with_alignments = ds_test.add_column(\n",
    "    \"alignments\",\n",
    "    metric_result[\"alignments\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e0d6970ebe54a67ac69e4b9b565eeff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/11 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "linearize_annotations() got an unexpected keyword argument 'ID'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 37\u001b[0m\n\u001b[1;32m     33\u001b[0m     batch[\u001b[39m\"\u001b[39m\u001b[39mprediction_linear\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ls_prediction_linear\n\u001b[1;32m     35\u001b[0m     \u001b[39mreturn\u001b[39;00m batch\n\u001b[0;32m---> 37\u001b[0m ds_test_with_alignments \u001b[39m=\u001b[39m ds_test_with_alignments\u001b[39m.\u001b[39;49mmap(\n\u001b[1;32m     38\u001b[0m     _linearize_comp,\n\u001b[1;32m     39\u001b[0m     batched \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m     40\u001b[0m     batch_size \u001b[39m=\u001b[39;49m BATCH_SIZE,\n\u001b[1;32m     41\u001b[0m )\n\u001b[1;32m     43\u001b[0m ds_test_dump \u001b[39m=\u001b[39m ds_test_with_alignments\u001b[39m.\u001b[39mremove_columns(\n\u001b[1;32m     44\u001b[0m     [\n\u001b[1;32m     45\u001b[0m         col \u001b[39mfor\u001b[39;00m col \u001b[39min\u001b[39;00m ds_test_with_alignments\u001b[39m.\u001b[39mcolumn_names\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     ]\n\u001b[1;32m     53\u001b[0m )\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/comparative-ner-utils-sv0RmVnD-py3.10/lib/python3.10/site-packages/datasets/arrow_dataset.py:2585\u001b[0m, in \u001b[0;36mDataset.map\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, num_proc, suffix_template, new_fingerprint, desc)\u001b[0m\n\u001b[1;32m   2582\u001b[0m disable_tqdm \u001b[39m=\u001b[39m \u001b[39mnot\u001b[39;00m logging\u001b[39m.\u001b[39mis_progress_bar_enabled()\n\u001b[1;32m   2584\u001b[0m \u001b[39mif\u001b[39;00m num_proc \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m num_proc \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m-> 2585\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_map_single(\n\u001b[1;32m   2586\u001b[0m         function\u001b[39m=\u001b[39;49mfunction,\n\u001b[1;32m   2587\u001b[0m         with_indices\u001b[39m=\u001b[39;49mwith_indices,\n\u001b[1;32m   2588\u001b[0m         with_rank\u001b[39m=\u001b[39;49mwith_rank,\n\u001b[1;32m   2589\u001b[0m         input_columns\u001b[39m=\u001b[39;49minput_columns,\n\u001b[1;32m   2590\u001b[0m         batched\u001b[39m=\u001b[39;49mbatched,\n\u001b[1;32m   2591\u001b[0m         batch_size\u001b[39m=\u001b[39;49mbatch_size,\n\u001b[1;32m   2592\u001b[0m         drop_last_batch\u001b[39m=\u001b[39;49mdrop_last_batch,\n\u001b[1;32m   2593\u001b[0m         remove_columns\u001b[39m=\u001b[39;49mremove_columns,\n\u001b[1;32m   2594\u001b[0m         keep_in_memory\u001b[39m=\u001b[39;49mkeep_in_memory,\n\u001b[1;32m   2595\u001b[0m         load_from_cache_file\u001b[39m=\u001b[39;49mload_from_cache_file,\n\u001b[1;32m   2596\u001b[0m         cache_file_name\u001b[39m=\u001b[39;49mcache_file_name,\n\u001b[1;32m   2597\u001b[0m         writer_batch_size\u001b[39m=\u001b[39;49mwriter_batch_size,\n\u001b[1;32m   2598\u001b[0m         features\u001b[39m=\u001b[39;49mfeatures,\n\u001b[1;32m   2599\u001b[0m         disable_nullable\u001b[39m=\u001b[39;49mdisable_nullable,\n\u001b[1;32m   2600\u001b[0m         fn_kwargs\u001b[39m=\u001b[39;49mfn_kwargs,\n\u001b[1;32m   2601\u001b[0m         new_fingerprint\u001b[39m=\u001b[39;49mnew_fingerprint,\n\u001b[1;32m   2602\u001b[0m         disable_tqdm\u001b[39m=\u001b[39;49mdisable_tqdm,\n\u001b[1;32m   2603\u001b[0m         desc\u001b[39m=\u001b[39;49mdesc,\n\u001b[1;32m   2604\u001b[0m     )\n\u001b[1;32m   2605\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   2607\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39mformat_cache_file_name\u001b[39m(cache_file_name, rank):\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/comparative-ner-utils-sv0RmVnD-py3.10/lib/python3.10/site-packages/datasets/arrow_dataset.py:585\u001b[0m, in \u001b[0;36mtransmit_tasks.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    583\u001b[0m     \u001b[39mself\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m=\u001b[39m kwargs\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mself\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    584\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    586\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    587\u001b[0m \u001b[39mfor\u001b[39;00m dataset \u001b[39min\u001b[39;00m datasets:\n\u001b[1;32m    588\u001b[0m     \u001b[39m# Remove task templates if a column mapping of the template is no longer valid\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/comparative-ner-utils-sv0RmVnD-py3.10/lib/python3.10/site-packages/datasets/arrow_dataset.py:552\u001b[0m, in \u001b[0;36mtransmit_format.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m self_format \u001b[39m=\u001b[39m {\n\u001b[1;32m    546\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mtype\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_type,\n\u001b[1;32m    547\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mformat_kwargs\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_kwargs,\n\u001b[1;32m    548\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mcolumns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_format_columns,\n\u001b[1;32m    549\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39moutput_all_columns\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_output_all_columns,\n\u001b[1;32m    550\u001b[0m }\n\u001b[1;32m    551\u001b[0m \u001b[39m# apply actual function\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m out: Union[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mDatasetDict\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    553\u001b[0m datasets: List[\u001b[39m\"\u001b[39m\u001b[39mDataset\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(out\u001b[39m.\u001b[39mvalues()) \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(out, \u001b[39mdict\u001b[39m) \u001b[39melse\u001b[39;00m [out]\n\u001b[1;32m    554\u001b[0m \u001b[39m# re-apply format to the output\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/comparative-ner-utils-sv0RmVnD-py3.10/lib/python3.10/site-packages/datasets/fingerprint.py:480\u001b[0m, in \u001b[0;36mfingerprint_transform.<locals>._fingerprint.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    476\u001b[0m             validate_fingerprint(kwargs[fingerprint_name])\n\u001b[1;32m    478\u001b[0m \u001b[39m# Call actual function\u001b[39;00m\n\u001b[0;32m--> 480\u001b[0m out \u001b[39m=\u001b[39m func(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    482\u001b[0m \u001b[39m# Update fingerprint of in-place transforms + update in-place history of transforms\u001b[39;00m\n\u001b[1;32m    484\u001b[0m \u001b[39mif\u001b[39;00m inplace:  \u001b[39m# update after calling func so that the fingerprint doesn't change if the function fails\u001b[39;00m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/comparative-ner-utils-sv0RmVnD-py3.10/lib/python3.10/site-packages/datasets/arrow_dataset.py:2982\u001b[0m, in \u001b[0;36mDataset._map_single\u001b[0;34m(self, function, with_indices, with_rank, input_columns, batched, batch_size, drop_last_batch, remove_columns, keep_in_memory, load_from_cache_file, cache_file_name, writer_batch_size, features, disable_nullable, fn_kwargs, new_fingerprint, rank, offset, disable_tqdm, desc, cache_only)\u001b[0m\n\u001b[1;32m   2978\u001b[0m indices \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\n\u001b[1;32m   2979\u001b[0m     \u001b[39mrange\u001b[39m(\u001b[39m*\u001b[39m(\u001b[39mslice\u001b[39m(i, i \u001b[39m+\u001b[39m batch_size)\u001b[39m.\u001b[39mindices(input_dataset\u001b[39m.\u001b[39mnum_rows)))\n\u001b[1;32m   2980\u001b[0m )  \u001b[39m# Something simpler?\u001b[39;00m\n\u001b[1;32m   2981\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 2982\u001b[0m     batch \u001b[39m=\u001b[39m apply_function_on_filtered_inputs(\n\u001b[1;32m   2983\u001b[0m         batch,\n\u001b[1;32m   2984\u001b[0m         indices,\n\u001b[1;32m   2985\u001b[0m         check_same_num_examples\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(input_dataset\u001b[39m.\u001b[39;49mlist_indexes()) \u001b[39m>\u001b[39;49m \u001b[39m0\u001b[39;49m,\n\u001b[1;32m   2986\u001b[0m         offset\u001b[39m=\u001b[39;49moffset,\n\u001b[1;32m   2987\u001b[0m     )\n\u001b[1;32m   2988\u001b[0m \u001b[39mexcept\u001b[39;00m NumExamplesMismatchError:\n\u001b[1;32m   2989\u001b[0m     \u001b[39mraise\u001b[39;00m DatasetTransformationNotAllowedError(\n\u001b[1;32m   2990\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUsing `.map` in batched mode on a dataset with attached indexes is allowed only if it doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt create or remove existing examples. You can first run `.drop_index() to remove your index and then re-add it.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   2991\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/comparative-ner-utils-sv0RmVnD-py3.10/lib/python3.10/site-packages/datasets/arrow_dataset.py:2865\u001b[0m, in \u001b[0;36mDataset._map_single.<locals>.apply_function_on_filtered_inputs\u001b[0;34m(inputs, indices, check_same_num_examples, offset)\u001b[0m\n\u001b[1;32m   2863\u001b[0m \u001b[39mif\u001b[39;00m with_rank:\n\u001b[1;32m   2864\u001b[0m     additional_args \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (rank,)\n\u001b[0;32m-> 2865\u001b[0m processed_inputs \u001b[39m=\u001b[39m function(\u001b[39m*\u001b[39;49mfn_args, \u001b[39m*\u001b[39;49madditional_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfn_kwargs)\n\u001b[1;32m   2866\u001b[0m \u001b[39mif\u001b[39;00m update_data \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2867\u001b[0m     \u001b[39m# Check if the function returns updated examples\u001b[39;00m\n\u001b[1;32m   2868\u001b[0m     update_data \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(processed_inputs, (Mapping, pa\u001b[39m.\u001b[39mTable))\n",
      "File \u001b[0;32m~/.cache/pypoetry/virtualenvs/comparative-ner-utils-sv0RmVnD-py3.10/lib/python3.10/site-packages/datasets/arrow_dataset.py:2545\u001b[0m, in \u001b[0;36mDataset.map.<locals>.decorate.<locals>.decorated\u001b[0;34m(item, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2541\u001b[0m decorated_item \u001b[39m=\u001b[39m (\n\u001b[1;32m   2542\u001b[0m     Example(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures) \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m batched \u001b[39melse\u001b[39;00m Batch(item, features\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeatures)\n\u001b[1;32m   2543\u001b[0m )\n\u001b[1;32m   2544\u001b[0m \u001b[39m# Use the LazyDict internally, while mapping the function\u001b[39;00m\n\u001b[0;32m-> 2545\u001b[0m result \u001b[39m=\u001b[39m f(decorated_item, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   2546\u001b[0m \u001b[39m# Return a standard dict\u001b[39;00m\n\u001b[1;32m   2547\u001b[0m \u001b[39mreturn\u001b[39;00m result\u001b[39m.\u001b[39mdata \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, LazyDict) \u001b[39melse\u001b[39;00m result\n",
      "Cell \u001b[0;32mIn[7], line 18\u001b[0m, in \u001b[0;36m_linearize_comp\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m      9\u001b[0m     ID \u001b[39m=\u001b[39m batch[\u001b[39m\"\u001b[39m\u001b[39mID\u001b[39m\u001b[39m\"\u001b[39m][i]\n\u001b[1;32m     10\u001b[0m     tokens \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(\n\u001b[1;32m     11\u001b[0m                 itertools\u001b[39m.\u001b[39mtakewhile(\n\u001b[1;32m     12\u001b[0m             \u001b[39mlambda\u001b[39;00m t: t \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m (\u001b[39m\"\u001b[39m\u001b[39m[SEP]\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m[PAD]\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[1;32m     13\u001b[0m             batch[\u001b[39m\"\u001b[39m\u001b[39mtoken_subwords\u001b[39m\u001b[39m\"\u001b[39m][i]\n\u001b[1;32m     14\u001b[0m         )\n\u001b[1;32m     15\u001b[0m     )\n\u001b[1;32m     17\u001b[0m     ls_reference_linear\u001b[39m.\u001b[39mappend(\n\u001b[0;32m---> 18\u001b[0m         aoc\u001b[39m.\u001b[39;49mlinearize_annotations(\n\u001b[1;32m     19\u001b[0m             tokens,\n\u001b[1;32m     20\u001b[0m             batch[\u001b[39m\"\u001b[39;49m\u001b[39mcomp_subword_aligned\u001b[39;49m\u001b[39m\"\u001b[39;49m][i],\n\u001b[1;32m     21\u001b[0m             ID \u001b[39m=\u001b[39;49m ID,\n\u001b[1;32m     22\u001b[0m         )\n\u001b[1;32m     23\u001b[0m     )\n\u001b[1;32m     24\u001b[0m     ls_prediction_linear\u001b[39m.\u001b[39mappend(\n\u001b[1;32m     25\u001b[0m         aoc\u001b[39m.\u001b[39mlinearize_annotations(\n\u001b[1;32m     26\u001b[0m             tokens,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m         )\n\u001b[1;32m     30\u001b[0m     )\n\u001b[1;32m     32\u001b[0m batch[\u001b[39m\"\u001b[39m\u001b[39mreference_linear\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m ls_reference_linear\n",
      "\u001b[0;31mTypeError\u001b[0m: linearize_annotations() got an unexpected keyword argument 'ID'"
     ]
    }
   ],
   "source": [
    "def _linearize_comp(\n",
    "    batch: datasets.arrow_dataset.Batch\n",
    ") -> datasets.arrow_dataset.Batch:\n",
    "    ls_reference_linear = []\n",
    "    ls_prediction_linear = []\n",
    "    batch_size = len(batch[\"ID\"])\n",
    "\n",
    "    for i in range(batch_size):\n",
    "        ID = batch[\"ID\"][i]\n",
    "        tokens = tuple(\n",
    "                    itertools.takewhile(\n",
    "                lambda t: t not in (\"[SEP]\", \"[PAD]\"),\n",
    "                batch[\"token_subwords\"][i]\n",
    "            )\n",
    "        )\n",
    "\n",
    "        ls_reference_linear.append(\n",
    "            aoc.linearize_annotations(\n",
    "                tokens,\n",
    "                batch[\"comp_subword_aligned\"][i],\n",
    "            )\n",
    "        )\n",
    "        ls_prediction_linear.append(\n",
    "            aoc.linearize_annotations(\n",
    "                tokens,\n",
    "                batch[\"comp_predicted\"][i],\n",
    "            )\n",
    "        )\n",
    "\n",
    "    batch[\"reference_linear\"] = ls_reference_linear\n",
    "    batch[\"prediction_linear\"] = ls_prediction_linear\n",
    "\n",
    "    return batch\n",
    "\n",
    "ds_test_with_alignments = ds_test_with_alignments.map(\n",
    "    _linearize_comp,\n",
    "    batched = True,\n",
    "    batch_size = BATCH_SIZE,\n",
    ")\n",
    "\n",
    "ds_test_dump = ds_test_with_alignments.remove_columns(\n",
    "    [\n",
    "        col for col in ds_test_with_alignments.column_names\n",
    "        if col not in (\n",
    "            \"ID\",\n",
    "            \"prediction_linear\",\n",
    "            \"reference_linear\",\n",
    "            \"alignments\",\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = ruamel.yaml.YAML()\n",
    "with open(\"./result.yaml\", \"w\") as f:\n",
    "    yaml.dump(\n",
    "        [entry for entry in ds_test_dump],\n",
    "        f\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_result[\"scores_spanwise\"] = { \n",
    "    str(k) : v\n",
    "    for k, v in metric_result[\"scores_spanwise\"].items()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7514495709808594"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result[\"F1_partial_average\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.629925369326653"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metric_result[\"F1_strict_average\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NERWithRootLabel.deg\n",
      "0.8033333333333333\n",
      "0.7266666666666666\n",
      "\n",
      "NERWithRootLabel.prej\n",
      "0.8713550600343053\n",
      "0.8164665523156088\n",
      "\n",
      "NERWithRootLabel.cont\n",
      "0.6441048034934499\n",
      "0.462882096069869\n",
      "\n",
      "NERWithRootLabel.diff\n",
      "0.8047337278106508\n",
      "0.7337278106508877\n",
      "\n",
      "NERWithRootLabel.root\n",
      "0.6337209302325582\n",
      "0.4098837209302326\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for label, res in metric_result[\"scores_spanwise\"].items():\n",
    "    print(label)\n",
    "    print(res[\"F1_partial\"])\n",
    "    print(res[\"F1_strict\"])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "yaml = ruamel.yaml.YAML()\n",
    "with open(\"scores.yaml\", \"w\") as g:\n",
    "    yaml.dump(\n",
    "        {\n",
    "            k : v for k, v in metric_result.items()\n",
    "            if k != \"alignments\"\n",
    "        },\n",
    "        stream = g,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('comparative-ner-utils-sv0RmVnD-py3.10')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "98ff88495b25d3c68e7ba2c5383ef33c76229d3a0872ace53e941ddd39c21b36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
